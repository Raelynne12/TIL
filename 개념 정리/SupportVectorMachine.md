# SVM(서포트벡터머신)

> 클래스를 잘 분류할 수 있는 최적의 벡터 선분을 찾는 알고리즘
>
> 최적의 벡터 선분 >>  초평면(hyper plane)
>
> 지지선(지지 벡터_서포트 벡터)
>
> 경계면(margin)을 최대로 하는 지지선을 찾는 것



hyper plane보다 위면 class1, 아래면  class2 (멀티클래스도 가능(다중 분류))



비선형 경계면 분류 > 선형으로 변환해야 함 > 매핑함수



매핑함수 사용시

- 데이터 > 선형적 형태로 변형
- 축 > 매우 복잡한 형태로 변형
- 차원의 저주가 발생할 수 있음
  - representer 정리 활용
    - 임의의 단조 증가 함수와 비음수 손실함수 활용



비선형 svm

- 적절한 카파(커널함수) 결정
- 비선형과 고차원 데이터에서 비선형 결정경계를 갖는 모형 생성
- 의사결정나무는 엔트로피에서 데이터를 선형으로 구분 
  - 데이터가 비선형일 경우 오분류 다수 발생
- 해결 방법 > 비선형 svm



차원축소

- 차원의 저주 피하기 위해
- pca(주성분 분석)
  - 많은 변수로 구성된 데이터에 주성분이라는 새로운 변수 생성해서 기존 변수들보다 차원 축소해서 분석 수행
  - **새로운 축 설계**
  - 정보 최대로 유지하면서 관련성 분석해서 해석 가능한 적은 개수의 새로운 변수들로 축소
  - 데이터 셋에서 feature 별로 표준화(평균 빼고 분산 나누기)
  - feature data의 공분산 행렬 구하기
  - 공분산 행렬의 **고유값(분산의 크기), 고유 벡터(분산 방향)** 구하기
  - 고유값이 큰 순서대로 내림차순 정렬
  - d차원 줄이고 싶을 때 : 크기 순서대로 d개 고유값 선정
  - 고유벡터로 새로운 행렬 생성
  - 원본 데이터를 새로운 행렬에 투영(projection)