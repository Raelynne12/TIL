# 데이터 마이닝

> 대용량 데이터에서 의미있는 데이터 패턴을 파악하거나
>
> 예측을 위해 데이터를 자동으로 분석해서 의사결정에 활용



\>> 변수를 줄여가는 게 목적



**통계 vs 데이터마이닝**

통계

- 가설을 명제형태로 만들어서 세우고(영가설/귀무가설), 대립가설(연구가설) 차이가 있다고 하는 게 목적
- 보수적 관점(하나씩 디테일하게)

데이터 마이닝

- 가장 의미 있는 걸 뽑는 거(pca분석/유인분석)
- 서로 비슷한 것들끼리 묶어서

train data | test data (0.7:0.3)

fine tuning(미세 조정) > 로버스트(튼튼하게 만듦) >> 모형접근법



**개요**

\- 회귀분석 / 로짓분석 / 최근접 이웃(KNN) / 인공지능 / 의사결정나무(직관적/이분법적, 가지치기) / k-평균군집화(k>하이퍼파라미터) / 연관분석(if~then)



**특징**

- 분석 대상이나 활용 목적, 표현 방법에 따라
  - 시각화 분석, 분류, 군집화, ...





**학습법**

- 지도학습
  - supervised learning
  - label 
  - 정답을 알려주면서 학습
  - 출력변수 있음
- 비지도학습
  - unsupervised learning
  - 군집분석
  - 정답 안알려주고 비슷한 데이터 군집화 > 미래 예측
  - 출력변수 없음



**추진단계**

1. 목적정의
2. 데이터 준비
   - 데이터가 충분한가(나중에 프로젝트할 때 api나 공공데이터를 이용해서 해야)
   - 관심사가 비슷한가
3. 데이터 가공(중요)
4. 데이터마이닝 기법 적용(model)(모델을 목적에 맞게 선택)
5. 검증(성능평가)

\- 평가하는 사람들은 4, 5번 봄(가공 잘 못하면 검증에서 성능 안좋게 나옴)



**데이터 분할**

- 훈련용(training)
  - 초기 데이터마이닝 모델 만드는데 사용 (추정용, 훈련용)

- 검정용(validation)
  - 구축된 모델의 과잉(overfitting) 또는 과소맞춤 등의 미세조정 절차를 위해
- 시험용(test)
  - 데이터마이닝 추진 5단계에서 검증용으로 사용

\- 실제로는 train/test(hold out절대 만지면 안돼) 이렇게 두 갠데 kaggle에서 세 개로 세분화(검정용)

\- 데이터셋이 작을 경우 > 필요에 따라 훈련용과 시험용을 번갈아가며 사용

   \>> 교차확인(cross )을 통해서 



**모형평가**

\- 몇 가지 모형 중 어느 것이 적합한지 판단하는 기준 >> 손익비교

\- 모델링은 변경 주기 O, 정확도의 편차가 급증하는 시점에 실행(최소 1년 두 번)



**분류분석**

- 목적 : 반응변수(종속변수)가 알려진 다변량 자료를 이용해서 모형 구축 > 새로운 자료에 대한 예측 및 분류
- 모형 : 로지스틱회귀모형, 신경망모형, 의사결정나무모형, 앙상블모형(케글에서 많이 씀), 규칙기반분류, 사례기반분류, 인접이웃분류모형, 베이즈분류모형, 유전자 알고리즘



**분류 vs 예측**





**의사결정나무**

\- 뿌리 마디 / 부모 마디 / 자식 마디 / 최종마디(끝마디) / 중간 마디 / 가지 / 깊이

\- 결정 규칙

- 분할 규칙
  - 새 가지를 어디에서 나오게 할까
- 정지 규칙
  - 어떤 기준을 만족하면 새 가지가 더 이상 못나오게 하는가
- 가지치기 규칙
  - 어느 가지를 쳐내야 예측력 높은 나무가 되는가

\- 특징

1. 설명 용이
2. 시각화해서 한 눈에 볼 수 있음
3. 계산적으로 복잡하지 않아서 대용량 데이터에서도 빠르게 만들 수 있음
4. 분류 작업 빠르게
5. 잡음 데이터에 대해서도 민감함없이 분류 가능
6. 정확도 높음
7. 비모수적 모형(비모수 통계)
8. 수치형/범주형 변수를 모두 사용할 수 있음
8. 너무 깊이가 깊어질수록  과적합



\- 지니 계수(gini index) : 특정 클래스에 속하는 데이터의 비율을 모두 제외한 값 >> 다양성을 계산하는 방법

​										  yes확률 제곱 - no확률 제곱

지니 불순도(gini impurity)    <<  **계산하는 거 시험에 낼거래**

\>> 가장 불순도가 낮게 나오는 기준을 선택

깊이가 깊어질수록 세분화해서 나눌 수 있지만 과적합 가능성 있음



암이 아닌데 암 > 2형 오류

**1형 오류 2형 오류 이거 시험나옴**



\- 엔트로피  : 불순도를 수치화한 지표 중 하나 > 불확실성을 수치로 나타낸 것

1. 엔트로피 수치가 0이면 > 분류할 필요없음(이물질이 없음)
2. 엔트로피 수치가 1이면 > 불순도 높다
3. 엔트로피 수치가 0에 가까우면 > 불순도가 낮다

이 엔트로피를 이용해서 정보획득량(information gain)을 구하게 됨

\- 정보획득량 = 분할 전 엔트로피 - 분할 후 엔트로피

정보획득량이 크면 > 불순도가 줄어든다



\- rpart 패키지 : CART(classification and regression trees) 방법론을 사용해서 의사결정나무 구현



\- party패키지 : p-value 이용해서 가지를 만들기 때문에 가지치기할 필요 없음



**오분류표** : 목표 변수의 실제 범주와 모형에 의해 예측된 분류 범주 사이의 관계를 나타내는 표

\- TP/TN/FP/FN

- 정밀도
  - precision
  - TP
  - negative가 중요한 경우
    - 일반 메일을 스팸 메일로 잘못 예측했을 경우 중요한 메일을 전달받지 못하는 상황이 생길 수 있음
- 정확도
  - accuracy
  - TP+TN
- 재현율 = 민감도
  - recall = sensitivity
  - TP
  - positive가 중요한 경우
    - 악성 종양을 양성 종양으로 잘못 예측했을 경우 제 때 치료를 받지 못하게 되어 생명이 위급해질 수 있음
- 특이도
  - specificity
  - TN

\- 오차행렬(confusion matrix) : 데이터 실제 클래스와 모델에 의해 예측된 클래스를 비교하는 행렬

​												      **F1-score**

(여기 좀 더 채워야 함)



혼동 행렬 > 분류 결과를 전체적으로

정확도 >  정답을 얼마나 잘 맞췄는지

정밀도, 재현율 >  

(여기도 채워)



---



### 로지스틱 회귀분석



1. 모델을 이용한 예측 및 결과값 출력
2. 예측 결과와 실제 결과값 비교
3. 예측 정확도 계산 및 출력



시그모이드 : 이진분류

소프트맥스 : 다중분류



**시그모이드** : s자형 곡선 or 시그모이드 곡선을 갖는 수학 함수 / 가역 함수(역은 로짓함수)

-특징

- 실함수로써 미분 가능
- 음이 아닌 미분값을 가지고, 단 하나의 변곡점 가짐
- 일반적으로 단조함수
- 종 모양의 1차 미분 그래프
- x가 무한으로 갈 때 한 쌍의 수평 점근선으로 수렴
- 0보다 작은 값에서 볼록하고, 0보다 큰 값에서 오목



**소프트맥스**(nomalized expotential function) : 

\- 특징

- 시그모이드 함수의 일반화
- 확률이론이나 확률적 머신이론에 활용

(여기도 채워)



---



### 앙상블

> 여러 개 분류모형에 의한 결과를 종합해서 분류의 정확도 높임



**특징**

- 과적합 가능성 줄여줌
- 평균 취함으로써 편의 제거
- 변동성 작아짐(한 개 모형으로부터 여러 모형의 의견을 결합하면)



**생긴 이유**

- 나무 모형의 불안정성
- 분기변수 선택 문제
- 분기변수 변화에 따라 모형이 크게 달라짐(불안정성 야기)



**기본 형태**

- 부트스트랩 표본 추출로 다수의 훈련자료 생성
- 각 훈련자료에 대해 동일한 알고리즘으로 모형 생성
- 결과 결합해서 최종 예측치 산출



**용어 설명**

1. 배깅(bagging)
   - 여러 개 부트스트랩 자료 생성
   - 각 부트스트랩 자료에서 예측 모형 만든 후 결합 > 최종 예측 모형 
   - 랜덤 포레스트
     - 임의성
     - 예측력 향상
     - 투표 방법(voting) : 규칙이나 조건문을 토대로 나무 구조를 도표화해서 분류, 예측
2. 부트스트랩(bootstrap)
   - 동일한 크기의 표본은 무작위 복원추출(난수)로 뽑은 자료
3. 부스팅(boosting)
   - 예측력 약한 모형들 결합해서 강한 예측 모형 만들기
   - 훈련 오차를 빨리, 쉽게 줄일 수 있음
   - 예측오차가 적어져서 성능 향상



