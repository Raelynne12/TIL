# 데이터 마이닝

> 대용량 데이터에서 의미있는 데이터 패턴을 파악하거나
>
> 예측을 위해 데이터를 자동으로 분석해서 의사결정에 활용



\>> 변수를 줄여가는 게 목적



**통계 vs 데이터마이닝**

통계

- 가설을 명제형태로 만들어서 세우고(영가설/귀무가설), 대립가설(연구가설) 차이가 있다고 하는 게 목적
- 보수적 관점(하나씩 디테일하게)

데이터 마이닝

- 가장 의미 있는 걸 뽑는 거(pca분석/유인분석)
- 서로 비슷한 것들끼리 묶어서

train data | test data (0.7:0.3)

fine tuning(미세 조정) > 로버스트(튼튼하게 만듦) >> 모형접근법



**개요**

\- 회귀분석 / 로짓분석 / 최근접 이웃(KNN) / 인공지능 / 의사결정나무(직관적/이분법적, 가지치기) / k-평균군집화(k>하이퍼파라미터) / 연관분석(if~then)



**특징**

- 분석 대상이나 활용 목적, 표현 방법에 따라
  - 시각화 분석, 분류, 군집화, ...





**학습법**

- 지도학습
  - supervised learning
  - label 
  - 정답을 알려주면서 학습
  - 출력변수 있음
- 비지도학습
  - unsupervised learning
  - 군집분석
  - 정답 안알려주고 비슷한 데이터 군집화 > 미래 예측
  - 출력변수 없음



**추진단계**

1. 목적정의
2. 데이터 준비
   - 데이터가 충분한가(나중에 프로젝트할 때 api나 공공데이터를 이용해서 해야)
   - 관심사가 비슷한가
3. 데이터 가공(중요)
4. 데이터마이닝 기법 적용(model)(모델을 목적에 맞게 선택)
5. 검증(성능평가)

\- 평가하는 사람들은 4, 5번 봄(가공 잘 못하면 검증에서 성능 안좋게 나옴)



**데이터 분할**

- 훈련용(training)
  - 초기 데이터마이닝 모델 만드는데 사용 (추정용, 훈련용)

- 검정용(validation)
  - 구축된 모델의 과잉(overfitting) 또는 과소맞춤 등의 미세조정 절차를 위해
- 시험용(test)
  - 데이터마이닝 추진 5단계에서 검증용으로 사용

\- 실제로는 train/test(hold out절대 만지면 안돼) 이렇게 두 갠데 kaggle에서 세 개로 세분화(검정용)

\- 데이터셋이 작을 경우 > 필요에 따라 훈련용과 시험용을 번갈아가며 사용

   \>> 교차확인(cross )을 통해서 



**모형평가**

\- 몇 가지 모형 중 어느 것이 적합한지 판단하는 기준 >> 손익비교

\- 모델링은 변경 주기 O, 정확도의 편차가 급증하는 시점에 실행(최소 1년 두 번)



**분류분석**

- 목적 : 반응변수(종속변수)가 알려진 다변량 자료를 이용해서 모형 구축 > 새로운 자료에 대한 예측 및 분류
- 모형 : 로지스틱회귀모형, 신경망모형, 의사결정나무모형, 앙상블모형(케글에서 많이 씀), 규칙기반분류, 사례기반분류, 인접이웃분류모형, 베이즈분류모형, 유전자 알고리즘



**분류 vs 예측**





**의사결정나무**

\- 뿌리 마디 / 부모 마디 / 자식 마디 / 최종마디(끝마디) / 중간 마디 / 가지 / 깊이

\- 결정 규칙

- 분할 규칙
  - 새 가지를 어디에서 나오게 할까
- 정지 규칙
  - 어떤 기준을 만족하면 새 가지가 더 이상 못나오게 하는가
- 가지치기 규칙
  - 어느 가지를 쳐내야 예측력 높은 나무가 되는가

\- 특징

1. 설명 용이
2. 시각화해서 한 눈에 볼 수 있음
3. 계산적으로 복잡하지 않아서 대용량 데이터에서도 빠르게 만들 수 있음
4. 분류 작업 빠르게
5. 잡음 데이터에 대해서도 민감함없이 분류 가능
6. 정확도 높음
7. 비모수적 모형(비모수 통계)
8. 수치형/범주형 변수를 모두 사용할 수 있음

