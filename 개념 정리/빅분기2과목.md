## 1. 데이터 정제



**데이터 관련 정의**

- 데이터
- 단위(Unit)
- 관측값(Observation)
- 변수(Variable)
- 원자료



**데이터 종류**

1. 단변량자료 - 자료 특성 대표하는 특성 변수가 하나인 자료
2. 다변량자료 - 자료 특성 대표하는 특성 변수가 두 개 이상인 자료
3. 질적자료 - 정성적 or 범주형 자료 >> 부여된 수치의 크기 자체에는 의미부여 x
   - 명목자료 : 측정 대상이 범주나 종류에 대해 구분되어지는 것을 수치, 기호로 분류(≠, =)
   - 서열자료 : 명목자료랑 비슷하지만, 수치나 기호가 서열을 나타냄(≠, =, ≤, ≥)
4. 수치자료 - 정량적 or 연속형 자료 >> 숫자의 크기에 의미 부여할 수 있는 자료
   - 구간자료 : 명목자료, 서열자료 포함하면서 변수 간 산술적 의미 가짐(≠, =, ≤, ≥, +, -)
   - 비율자료 : 명목, 서열, 구간 다 포함하면서 비율의 개념 도입(≠, =, ≤, ≥, +, -, ×, ÷)
5. 시계열 자료
6. 횡적자료 - 특정 단일시점에서 여러 대상으로부터 수집된 자료(한 시점에서 여러 대상으로부터 취합)
7. 종적자료 - 시계열 + 횡적 > 여러 개체를 여러 시점에서 수집한 자료



**데이터 정제**

- 정제 과정 거치지 않은 데이터 문제점 	
  - 일관성 없어지므로 분석 처리 어려워짐
  - 도출된 결과 신뢰성 저하
- 데이터 정제 과정
  - 정형보다 비정형 데이터가 많기 때문에 구조화된 정형 데이터로 변환하고 결측치나 오류를 수정해야
- 전처리와 후처리
  - 전처리 : 대상 데이터와 입수방법 결정 및 저장방식 장소 선택
  - 후처리 : 저장 데이터의 품질관리 등의 과정 포함



**데이터 결측값 처리**

> 결측치를 임의로 제거 > 분석에 필요한 유의수준 데이터 수집에 실패할 수 ㅇ
>
> 결측치를 임의로 대체 > 편향이 발생해서 신뢰성 저하될 수 ㅇ



**결측 데이터 종류**

1. 완전 무작위 결측(MCAR)
   - 다른 변수와 아무런 연관이 없는 경우
   - 나이대와 성별과 체중에 관계없이 체중이 없는 경우 > 데이터 누락 > 완전 무작위 결측
2. 무작위 결측(MAR)
   - 연관되어 있지만, 그 자체가 비관측값들과는 연관되지 않은 경우
   - 여성은 체중 공개를 꺼려하는 경향 > 체중이 누락될 가능성이 성별에만 의존 > 무작위 결측
   - 젊은 여성은 체중 공개를 꺼려하는 경향 > 무작위 결측
3. 비 무작위 결측(NMAR)
   - 결측변수값이 결측여부와 관련이 있는 경우
   - 체중이 많이 나가는 사람들은 체중 공개를 꺼려하는 경향 > 체중이 누락될 가능성이 체중값 자체에 관찰되지 않는 값에 달려있음 > 비 무작위 결측 



**결측값 유형의 분석 및 대치**

> 결측치가 존재하는 데이터를 이용한 분석은 효율성 문제, 자료처리의 복잡성, 편향 문제가 발생

1. 단순대치법

   - 기본적으로 결측치에 대해서 MCAR 또는 MAR로 판단하고 처리
   - 완전 분석
     - 불완전 자료는 완전 무시
     - 용이성 보장하지만 효율성 상실, 통계적 추론의 타당성에 문제 발생
   - 평균 대치법
     - 표준오차가 과소 추정되는 단점
   - 회귀 대치법
   - 단순확률 대치법
     - Hot-deck방법
     - 평균 대치법 단점 보완
     - 확률 추출에 의해서 전체 데이터 중 무작위로 대치
   - 최근접 대치법
     - 응답이 여러 번 사용될 가능성 ㅇ
     - 몇 개의 대체군으로 분류 > 각 층에서 정리하고 결측값 바로 이전의 응답을 결측치로 대치

2. 다중 대치법

   - 단순대치를 복수로 수행

   1. 대치단계
   2. 분석단계
   3. 결합단계



**이상치 종류**

- 단변수 이상치
  - 하나의 데이터 분포에서 발생하는 이상치
- 다변수 이상치
  - 복수의 연결된 데이터 분포공간에서 발생하는 이상치



**이상치 발생 원인**

- 비자연적 이상치 발생
  - 입력실수
  - 측정오류
  - 실험오류
  - 의도적 이상치
  - 자료처리오류
  - 표본오류
    - 편향이 발생하는 경우
- 이외에 발생하는 이상치들은 자연적 이상치



**이상치 문제점**

1. 기초(통계적) 분석결과의 신뢰도 저하
   - 평균, 분산 등에 영향을 줌(중앙값은 영향 적음)
2. 기초통계에 기반한 다른 고급 통계분석의 신뢰성 저하
   - 검정 추정 등의 분석, 회귀분석에 영향을 줌

- 특히 이상치가 비무작위성을 가지고 나타나게 되면, 정상성 감소를 초래 > 데이터 자체의 신뢰성 저하로 연결



**이상치 탐지**

> 종속변수가 단변량인지 다변량인지, 데이터 분포를 고려해서 모수적인지 비모수적인지에 따라 갈림

1. 시각화를 통한 방법(비모수적, 단변량 경우)
   - 상자수염그림
   - 줄기 - 잎 그림
   - 산점도 그림
2. Z-Score를 통한 방법(모수적 단변량 or 저변량 경우)
   - 정규화를 통해 특정 쓰레드를 벗어난 경우를 이상치로
3. 밀도기반 클러스터링 방법(DBSCAN)(비모수적 다변량 경우)
   - 군집간 밀도 이용해서 데이터 수가 지정 개수 이상이면 군집으로 정의
   - 군집에서 먼거리에 있는 데이터는 이상치
4. 고립 의사나무 방법(비모수적 다변량 경우)
   - 의사결정나무 기반
   - 정상치의 단말 노드보다 이상치의 노드에 이르는 길이가 더 짧은 성질 이용



---



## 2. 분석 변수 처리



**변수별 모형 분류**

1. 전체 모형(FM) : 모든 독립변수 사용한 모형
2. 축소 모형(RM) : 전체 모형에서 사용된 변수의 개수를 줄여서 얻은 모형
3. 영 모형(NM) : 독립변수가 하나도 없는 모형



**변수 선택 방법**

1. 전진 선택법
   - 영모형에서 시작 > 종속변수와 단순상과계수의 절대값이 가장 큰 변수를 분석모형에 포함
   - 부분 F 검정 통해 유의성 검증 > 유의하지 않은 경우는 변수선택 없이 중단
   - 한 번 추가된 변수는 제거 안됨
2. 후진 선택법
   - 전체모델에서 시작 > 종속변수와 단순상관계수의 절대값이 가장 작은 변수를 분석 모형에 포함
   - 부분 F 검정 통해 유의성 검증 > 유의한 경우는 변수제거 없이 중단
   - 한 번 제거된 변수는 추가 안됨
3. 단계적 선택법
   - 전진과 후진 보완법
   - 전진으로 가장 유의한 변수 모형에 포함 > 나머지는 후진 선택법 > 새롭게 유의하지 않은 변수들 제거
   - 유의한 설명변수가 존재하지 않을 때까지 과정 반복



**차원 축소**

> 데이터 종류의 양을 줄이는 것



**차원 축소 필요성**

1. 복잡도의 축소
   - 분석시간 증가(시간복잡도)와 저장변수 양 증가(공간복잡도) 고려한다면 효율성 측면에서 데이터 종류 수 줄여야 함
2. 과적합 방지
   - 분석모델 파라미터의 증가 및 파라미터 간 복잡한 관계 증가로 과적합 발생 가능성 ㅇ
   - 정확도(신뢰도) 저하될 수 ㅇ
3. 해석력 확보
   - 차원이 작은 간단한 분석모델일수록 이해 쉽고 해석 쉬워짐
4. 차원의 저주
   - 알고리즘 통한 학습 위해 차원 증가하면서 학습데이터 수가 차원 수보다 적어져서 성능 저하됨
   - 차원 줄이거나 데이터 수 늘려야 함



**차원 축소 방법**

1. 요인 분석

   - 다수의 변수들 간 상관관계 분석해서 공통차원 축약하는 통계분석
   - 변수 특성 파악 : 관련된 변수들이 군집으로서 요인 간 상호 동립성 파악이 용이해짐
   - 독립변수, 종속변수 개념이 없음
   - 주성분 분석, 공통요인 분석 특이값 분해(SVD), 음수미포함 행렬분해(NMF) 등
   - 공통 요인 분석 : 변수들이 가지고 있는 공통분산만을 이용해서 공통요인만 추출

   1. 주성분 분석
      - 특성을 설명할 수 있는 하나 OR 복수 개의 특징(주성분) 찾는 것
      - 서로 연관성 있는 고차원공간의 데이터를 선형연관성이 없는 저차원으로 변환하는 과정(직교변환)
      - 2차원 좌표평면에 N개 점데이터들이 타원형으로 분포 > 분포 특성을 2개의 벡터로 설명
      - 어떠한 사전적 분포 가정의 요구 없음
      - 가장 큰 분산의 방향들이 주요 중심 관심으로 가정
      - 선형결합으로만 고려
      - 서로 상관 있을 때만 가능
      - 스케일에 대한 영향 큼 > 스케일링 필수
   2. 특이값 분해(SVD)
      - M = U∑Vt(전치)
      - U : 직교행렬
      - ∑ : m × n 대각행렬(행렬 대각성분 제외한 나머지 행렬 원소의 값이 모두 0)
      - Vt : n × n 직교행렬(열벡터가 독립)
      - 기존 A 정보를 SVD에 의해 3개의 행렬로 분해 > 적당한 k값(특이값)만을 이용해서 A랑 비슷한 정보력 가지는 차원 만들기
      - 몇 개의 특이값을 가지고도 충분히 유용한 정보를 유지할 수 있는 차원을 생성
   3. 음수 미포함 행렬분해(NMF)
      - 음수를 포함하지 않은 행렬 V를 음수를 포함하지 않은 두 행렬의 곱으로 분해
      - W의 열개수와 H의 행개수가 WH = V가 되도록
      - 이 둘의 오차를 U라고 하면 V = WH + U (U는 양수 음수 될 수 있음)
      - W, H의 크기가 V보다 작아서 저장하거나 다루기 좋음(곱해지는 행렬은 훨씬 적은 차원 가짐)



**파생변수 생성**

> 파생변수 : 기존 변수 조합해서 새로운 변수 만들어내기
>
> 데이터마트 > 요약변수와 파생변수들의 모임

1. 파생변수
   - 특정 조건 만족하거나 특정 함수에 의해 값을 만들어 의미부여하는 함수
   - 매우 주관적이어서 논리적 타당성 갖춰야
   - 특정상황에만 유의미하지 않게 대표성을 나타내게 해야 함
2. 요약변수
   - 수집된 정보를 분석에 맞게 종합한 변수(aggregate)
   - 데이터마트에서 가장 기본적인 변수
   - 재활용성 높음(많은 분석 모델에서 공통으로 사용 ㅇ)
3. 요약변수 VS 파생변수
   1. 요약변수 처리 시 유의점
      - 처리 방법에 따라 결측치의 처리 및 이상값 처리에 유의해야
      - 연속형 변수의 구간화 적용과 고정된 구간화를 통한 의미 파악 시 정구간이 아닌 의미있는 구간 찾아야
   2. 파생변수 생성 방법
      - 한 값으로부터 특징 추출
      - 레코드 내의 값 결합
      - 다른 테이블의 부가적 정보 결합
      - 시간 종속적인 데이터 선택
      - 요약



**변수 변환**

> 데이터를 분석하기 좋은 형태로 바꿈
>
> 전처리 과정 중 하나



**변수 변환 방법**

1. 범주형 변환
   - 분석결과의 명료성 및 정확성 배가시키기 위해
2. 정규화
   - 스케일이 심하게 차이나는 경우 상대적 특성이 반영된 데이터로 변환하는 게 필요
   - 일반 정규화
   - 최소-최대 정규화
     - 가장 일반적
     - 최소값 0, 최대값 1
     - (X - Min) / (Max - Min)
     - 이상치 영향을 많이 받음
   - Z - score 정규화
     - 이상치 문제 피하는 정규화
     - Z = (X - μ) / σ
     - 데이터 값이 평균과 일치하면 0으로 정규화
     - 평균보다 작으면 음수, 크면 양수
     - 표준편차가 크면 정규화되는 값이 0에 가까워짐
   - 로그변환
     - 로그를 취하면 분포가 정규 분포에 가까워지는 경우에
     - X ~ ln(X)
     - 데이터 형태가 우측으로 치우친 경우
   - 역수 변환
     - X ~ 1/X
     - 극단적인 우측으로 치우친 경우
   - 지수변환
     - X ~ Xn
     - 좌측으로 치우친 경우
   - 제곱근변환
     - X ~ √X
     - 우측으로 약간 치우친 경우
   - 분포형태별 정규분포 변환
     - 정규성 검정은 눈으로 확인할 수 있지만 샤피로테스트, 큐큐플롯(Q-Q Plot) 이용해서 확인 ㅇ
     - 적당한 변수변환식 사용해서 정규분포 형태로 변환 ㅇ



**불균형 데이터 처리**

> 데이터 양에 차이가 큰 경우 클래스 불균형 있다고 함

- 문제점

  - 클래스 비율이 차이가 너무 나면 우세한 클래스를 택하는  모형의 정확도가 높아지므로 성능판별 어려워짐

  - 정확도가 높아도 데이터 개수가 적은 클래스 재현율이 급격히 작아짐

  - | TP   | FP   |
    | ---- | ---- |
    | FN   | TN   |

  - 정확도 : 전체 중에 맞은 확률

  - 재현율 : 사실이 참인 것 중 실험 결과가 참인 확률



**불균형 데이터 처리 방법**

1. 가중치 균형방법
   - 손실 계산할 때 특정 클래스의 데이터에 더 큰 손실값을 갖도록
   - 각 클래스별 특정 비율로 가중치 줘서 분석하거나 결과 도출
   - 고정 비율 이용
     - 클래스 비율에 따라 가중치
     - 적은 샘플 수를 가진 클래스를 전체 손실에 동일하게 기여하도록
     - 클래스 비율이 1 : 5면 가중치를 5 : 1로 줌
   - 최적 비율 이용
     - 분야와 최종 성능 고려해서 가중치 비율이 최적 세팅 찾으면서 가중치 찾아감
2. 언더샘플링과 오버샘플링
   - 언더샘플링
     - 대표클래스의 일부만 선택, 소수클래스는 최대한 많은 데이터 사용
     - 대표클래스는 대표성 있어야
   - 오버샘플링
     - 소수클래스 복사본 만들어서 대표클래스 수만큼 데이터 만드는 것
   - 데이터 비율 맞추면 정밀도 향상



---



## 3. 데이터 탐색의 기초



**EDA(탐색적 데이터 분석)**

- 데이터 분석 전 자료를 직관적인 방법으로 통찰하는 과정
- 필요성
  - 내재된 잠재적 문제에 대해 인식하고 해결안 도출
  - 문제정의 단계에서 인지 못한 새로운 양상, 패턴 발견 가능
- 분석과정 및 절차
  - 목적과 변수가 뭔지
  - 데이터의 문제성 확인(결측치 유무, 이상치 유무, head, tail부분 확인)
  - 개별 속성값이 예상한 범위 분포를 가지는지
  - 관계속성 확인 절차



**이상치 검출**

> 이상치가 왜 발생했는지 의미를 파악하는 게 중요

1. 개별 데이터 관찰

   - 패턴이 뒤에서 나타날 수도 있으므로 뒤나 무작위로 표본을 추출해서 관찰

2. 통계값 활용

   - 요약 통계지표 사용 가능
   - 중심을 알고 싶으면 평균, 중앙값, 최빈값 사용
   - 분산도를 알고 싶으면 범위, 분산 사용

   1. IQR 방법(사분위범위 이용한 이상치 제거)
      - 최대값 = 3사분위수 + 1.5 * IQR
      - 최소값 = 1사분위수 - 1.5 * IQR
   2. 정규분포를 활용(평균과 분산 이용한 이상치 제거)

3. 시각화 활용

   - 확률밀도함수, 히스토그램, 점플롯, 워드 클라우드, 시계열 차트, 지도 등

4. 머신러닝 기법 활용

   - K-means 통해 확인 가능



**변수 간 상관성 분석**

> 두 변수 간 어떤 선형적 관계를 가지고 있는지 분석
>
> 상관관계 : 두 변수 간 관계의 강도

1. 단순상관분석 : 단순히 두 개의 변수가 어느정도 강한 관계에 있는가
2. 다중상관분석 : 3개 이상 변수 간 관계강도 측정
   - 편상관관계분석 : 다중상관분석에서 다른 변수와의 관계 고정하고 두 변수 관계강도 측정



**상관분석 기본 가정**

1. 선형성 : 두 관계가 직선적인지  > 산점도를 통해 알 수 있음
2. 동변량성(등분산성) : x값에 관계없이 y의 흩어진 정도가 같은 것
   - 산포도가 특정 구간에 상관없이 퍼진 정도가 일정할 때 동변량성 띈다고 함
3. 두 변인의 정규분포성 : 두 변인의 측정치 분포가 모집단에서 모두 정규분포를 이루는
4. 무선독립표본 : 표본 뽑을 때 표본대상이 확률적으로 선정된다는 것



**상관분석 방법**

1. 피어슨 상관계수
   - x와 y 간의 선형 상관관계를 계량화한 수치
   - +1과 -1 사이의 값 가짐
   - +1은 완벽한 양의 선형 관계, 0은 상관관계 없음 -1은 완벽한 음의 선형 상관관계
2. 스피어만 상관계수
   - 서열자료인 경우, 데이터를 작은 것부터 차례로 순위를 매겨서 서열 순서로 바꾼 뒤 순위 이용해서 상관계수 
   - 두 변수 간 연관 관계 있는지 없는지 알려줌
   - 이상점 있거나 표본크기 작을 때 유용
   - 두 변수 차이가 클수록 스피어만 상관계수 값은 커짐
   - 1에 가까울수록 단조적 상관성(커지면 같이 증가)
   - 0에 가까우면 상관없 없음
   - 선형관계의 경우에는 직선 형태로 모형화 가능
   - 직선이 아니고 곡선 > 일정한 비율로 변화되는 게 아니다



**중심화 경향 기초통계량**

1. 산술평균
   - 그냥 일반적인 평균
2. 기하평균
   - n개 자료에 대해 관측치 곱한 후 n 제곱근으로 
3. 조화평균
   - 역수의 산술평균을 구한 후 다시 역수
   - 각자료가 동일하면 조화평균, 산술평균값과 기하평균값은 같음
   - 하지만 자료가 서로 다르면 조화 <= 기하 <= 산술 순서
4. 중앙값
   - 만약 n이 짝수이면 n/2번째와 n/2+1번째 자료의 평균을 중앙값으로
5. 최빈값
   - 질적자료, 양적자료 모두 사용
6. 분위수



**산포도(분산도)**

> 자료의 퍼짐 정도

1. 분산, 표준편차
   - 분산 : 평균을 중심으로 밀집되거나 퍼짐 정도 나타냄
     - 개개의 자료값에 대한 정보 반영
     - 특이점에 큰 영향 받음
   - 표준편차 : 분산의 제곱근
2. 범위
   - 최대값과 최소값 차이를 나타냄
   - 동일한 범위 갖더라고 자료의 분포모양은 다를 수 ㅇ
3. 평균 절대 편차(평균 편차(MAD), 절대 편차(MD))
   - 관측값에서 평균 빼고, 그 차이값에 절대값하고 , 그 값들 더해서 전체 개수 나눠준 거
   - 개개 자료값에 대한 정보 반영
   - 이상치 영향 적게 받음(범위보다)
   - 수리적으로 다루기 부적절(절대값으로 하기 때문에)
   - 평균 편차 클수록 자료는 폭넓게 분포
4. 사분위범위
   - 사분위범위 : Q3 - Q1
   - Q1 = (N+1) * (1/4)
   - 최대값 : Q3 + 1.5 * IQR
   - 최소값 : Q1 - 1.5 * IQR
5. 변동계수(CV)
   - 평균 중심으로 한 상대적인 산포의 척도
   - 측정 단위 같지만 평균에 차이 크게 보일 때 척도 비교하는 데 많이 사용
   - 클수록 상대적으로 넓게 분포
   - 표준편차/평균



**자료의 분포형태**

1. 왜도

   - 어느 한쪽으로 분포가 치우친 정도

   - 오른쪽으로 길면 양의 값, 왼쪽으로 길면 음의 값

   - | 음수 | 왼쪽으로 긴   | 평균 < 중앙값 < 최빈값 |
     | ---- | ------------- | ---------------------- |
     | 0    | 좌우 대칭     | 평균 = 중앙값 = 최빈값 |
     | 양수 | 오른쪽으로 긴 | 평균 > 중앙값 > 최빈값 |

   - 피어슨의 비대칭 계수

     - Cs = 3 * (평균 - 중앙값) / 표준편차
     - 0보다 크면 왼쪽으로 치우침, 오른쪽으로 긴 꼬리 > 정적편포
     - 0보다 작으면 오른쪽으로 치우침, 왼쪽으로 긴 고리 > 부적편포

2. 첨도

   - 분포의 뾰족한 정도
   - 3미만이면 평평, 3이면 정규분포, 3초과면 뾰족



**통계적 시각화 도구**

1. 도수분포표
   - 수집된 자료를 적절한 계급에 의해 분류해서 정리한 표
   - 도수 : 각 범주별 빈도
   - 상대도수 : 도수 / 전체자료 수
2. 히스토그램
3. 막대그래프
   - 도수 or 상대도수 그림으로 표현
4. 파이차트
5. 산점도
6. 줄기 잎 그림
   - 표와 그래프의 혼합된 방법
7. 상자수염 그림
   - 자료로부터 얻어낸 통계량(5가지 요약 수치) 가지고 그림
     - 최소값, Q1, Q2, Q3, 최대값



---



## 4. 고급 데이터 탐색



**다변량 데이터 탐색**

- 종속변수와 독립변수 사이의 인과관계
  1. 다중회귀
     - 독립변수 2개 이상인 회귀모형(각 독립변수는 종속변수와 선형관계에 있음을 가정)
     - 다중회귀분석을 통해 편이를 제거할 수 있음
     - 오차항의 평균은 0이라고 가정
     - 모수에 대해 선형이라고 가정
     - 오차항은 정규분포를 따르며 각 독립변수 역시 독립인 관계
     - 최소자승법을 이용해서 결과 도출
  2. 로지스틱 회귀
     - 사건의 발생 가능성을 예측하는 데 사용
     - 종속변수가 이항형 문제를 지칭할 때 사용
     - 이항형인 데이터에 적용했을 때 종속 변수 y의 결과가 0, 1로 제한
     - 종속 변수가 이진적이라서 조건부 확률의 분포가 정규분포가 아닌 이항 분포를 따름(시그모이드 함수)
  3. 분산분석(ANOVA)
     - 3개 이상 표본들의 차이를 표본평균 간 분산과 표본 내 관측치 간 분산을 비교해서 가설 검정
     - 일원분산분석(One way ANOVA) : 단 하나의 인자에 근거해서 여러 수준으로 나눠지는 분석
       - 종속변수와 정수값을 갖는 요인변수가 각 하나여야 하고 요인변수가 정의되어야
       - 독립변수에 의해 종속변수에 대한 평균치의 차이를 검정하는 데 이용
  4. 다변량 분석분석
     - 이원분산분석(Two way ANOVA) : 측정형 변수, 종속 변수가 2개 이상인 분산분석
       - 독립변인의 수가 두개 (일원분산분석과 다름)



**변수 축약**

1. 주성분분석(PCA)
   - 다변량자료에서 존재하는 비정규성이나 이상치 발견하기 위해 새로운 변수를 구하는 것
2. 요인분석
   - 다수 변수들의 상관관계 분석해서 공통차원들을 통해 축약해나감
   - 정보손실 최소화하면서 소수의 요인으로 축약
   - 독립변수와 종속변수 개념 없음
3. 정준상관분석
   - 두 변수집단 간 연관성을 각 변수집단에 속한 변수들의 선형결합의 상관계수 이용해서 분석
   - 인과성이 없음



**개체유도**

