## 1. 데이터 정제



**데이터 관련 정의**

- 데이터
- 단위(Unit)
- 관측값(Observation)
- 변수(Variable)
- 원자료



**데이터 종류**

1. 단변량자료 - 자료 특성 대표하는 특성 변수가 하나인 자료
2. 다변량자료 - 자료 특성 대표하는 특성 변수가 두 개 이상인 자료
3. 질적자료 - 정성적 or 범주형 자료 >> 부여된 수치의 크기 자체에는 의미부여 x
   - 명목자료 : 측정 대상이 범주나 종류에 대해 구분되어지는 것을 수치, 기호로 분류(≠, =)
   - 서열자료 : 명목자료랑 비슷하지만, 수치나 기호가 서열을 나타냄(≠, =, ≤, ≥)
4. 수치자료 - 정량적 or 연속형 자료 >> 숫자의 크기에 의미 부여할 수 있는 자료
   - 구간자료 : 명목자료, 서열자료 포함하면서 변수 간 산술적 의미 가짐(≠, =, ≤, ≥, +, -)
   - 비율자료 : 명목, 서열, 구간 다 포함하면서 비율의 개념 도입(≠, =, ≤, ≥, +, -, ×, ÷)
5. 시계열 자료
6. 횡적자료 - 특정 단일시점에서 여러 대상으로부터 수집된 자료(한 시점에서 여러 대상으로부터 취합)
7. 종적자료 - 시계열 + 횡적 > 여러 개체를 여러 시점에서 수집한 자료



**데이터 정제**

- 정제 과정 거치지 않은 데이터 문제점 	
  - 일관성 없어지므로 분석 처리 어려워짐
  - 도출된 결과 신뢰성 저하
- 데이터 정제 과정
  - 정형보다 비정형 데이터가 많기 때문에 구조화된 정형 데이터로 변환하고 결측치나 오류를 수정해야
- 전처리와 후처리
  - 전처리 : 대상 데이터와 입수방법 결정 및 저장방식 장소 선택
  - 후처리 : 저장 데이터의 품질관리 등의 과정 포함



**데이터 결측값 처리**

> 결측치를 임의로 제거 > 분석에 필요한 유의수준 데이터 수집에 실패할 수 ㅇ
>
> 결측치를 임의로 대체 > 편향이 발생해서 신뢰성 저하될 수 ㅇ



**결측 데이터 종류**

1. 완전 무작위 결측(MCAR)
   - 다른 변수와 아무런 연관이 없는 경우
   - 나이대와 성별과 체중에 관계없이 체중이 없는 경우 > 데이터 누락 > 완전 무작위 결측
2. 무작위 결측(MAR)
   - 연관되어 있지만, 그 자체가 비관측값들과는 연관되지 않은 경우
   - 여성은 체중 공개를 꺼려하는 경향 > 체중이 누락될 가능성이 성별에만 의존 > 무작위 결측
   - 젊은 여성은 체중 공개를 꺼려하는 경향 > 무작위 결측
3. 비 무작위 결측(NMAR)
   - 결측변수값이 결측여부와 관련이 있는 경우
   - 체중이 많이 나가는 사람들은 체중 공개를 꺼려하는 경향 > 체중이 누락될 가능성이 체중값 자체에 관찰되지 않는 값에 달려있음 > 비 무작위 결측 



**결측값 유형의 분석 및 대치**

> 결측치가 존재하는 데이터를 이용한 분석은 효율성 문제, 자료처리의 복잡성, 편향 문제가 발생

1. 단순대치법

   - 기본적으로 결측치에 대해서 MCAR 또는 MAR로 판단하고 처리
   - 완전 분석
     - 불완전 자료는 완전 무시
     - 용이성 보장하지만 효율성 상실, 통계적 추론의 타당성에 문제 발생
   - 평균 대치법
     - 표준오차가 과소 추정되는 단점
   - 회귀 대치법
   - 단순확률 대치법
     - Hot-deck방법
     - 평균 대치법 단점 보완
     - 확률 추출에 의해서 전체 데이터 중 무작위로 대치
   - 최근접 대치법
     - 응답이 여러 번 사용될 가능성 ㅇ
     - 몇 개의 대체군으로 분류 > 각 층에서 정리하고 결측값 바로 이전의 응답을 결측치로 대치

2. 다중 대치법

   - 단순대치를 복수로 수행

   1. 대치단계
   2. 분석단계
   3. 결합단계



**이상치 종류**

- 단변수 이상치
  - 하나의 데이터 분포에서 발생하는 이상치
- 다변수 이상치
  - 복수의 연결된 데이터 분포공간에서 발생하는 이상치



**이상치 발생 원인**

- 비자연적 이상치 발생
  - 입력실수
  - 측정오류
  - 실험오류
  - 의도적 이상치
  - 자료처리오류
  - 표본오류
    - 편향이 발생하는 경우
- 이외에 발생하는 이상치들은 자연적 이상치



**이상치 문제점**

1. 기초(통계적) 분석결과의 신뢰도 저하
   - 평균, 분산 등에 영향을 줌(중앙값은 영향 적음)
2. 기초통계에 기반한 다른 고급 통계분석의 신뢰성 저하
   - 검정 추정 등의 분석, 회귀분석에 영향을 줌

- 특히 이상치가 비무작위성을 가지고 나타나게 되면, 정상성 감소를 초래 > 데이터 자체의 신뢰성 저하로 연결



**이상치 탐지**

> 종속변수가 단변량인지 다변량인지, 데이터 분포를 고려해서 모수적인지 비모수적인지에 따라 갈림

1. 시각화를 통한 방법(비모수적, 단변량 경우)
   - 상자수염그림
   - 줄기 - 잎 그림
   - 산점도 그림
2. Z-Score를 통한 방법(모수적 단변량 or 저변량 경우)
   - 정규화를 통해 특정 쓰레드를 벗어난 경우를 이상치로
3. 밀도기반 클러스터링 방법(DBSCAN)(비모수적 다변량 경우)
   - 군집간 밀도 이용해서 데이터 수가 지정 개수 이상이면 군집으로 정의
   - 군집에서 먼거리에 있는 데이터는 이상치
4. 고립 의사나무 방법(비모수적 다변량 경우)
   - 의사결정나무 기반
   - 정상치의 단말 노드보다 이상치의 노드에 이르는 길이가 더 짧은 성질 이용



---



## 2. 분석 변수 처리



**변수별 모형 분류**

1. 전체 모형(FM) : 모든 독립변수 사용한 모형
2. 축소 모형(RM) : 전체 모형에서 사용된 변수의 개수를 줄여서 얻은 모형
3. 영 모형(NM) : 독립변수가 하나도 없는 모형



**변수 선택 방법**

1. 전진 선택법
   - 영모형에서 시작 > 종속변수와 단순상과계수의 절대값이 가장 큰 변수를 분석모형에 포함
   - 부분 F 검정 통해 유의성 검증 > 유의하지 않은 경우는 변수선택 없이 중단
   - 한 번 추가된 변수는 제거 안됨
2. 후진 선택법
   - 전체모델에서 시작 > 종속변수와 단순상관계수의 절대값이 가장 작은 변수를 분석 모형에 포함
   - 부분 F 검정 통해 유의성 검증 > 유의한 경우는 변수제거 없이 중단
   - 한 번 제거된 변수는 추가 안됨
3. 단계적 선택법
   - 전진과 후진 보완법
   - 전진으로 가장 유의한 변수 모형에 포함 > 나머지는 후진 선택법 > 새롭게 유의하지 않은 변수들 제거
   - 유의한 설명변수가 존재하지 않을 때까지 과정 반복



**차원 축소**

> 데이터 종류의 양을 줄이는 것



**차원 축소 필요성**

1. 복잡도의 축소
   - 분석시간 증가(시간복잡도)와 저장변수 양 증가(공간복잡도) 고려한다면 효율성 측면에서 데이터 종류 수 줄여야 함
2. 과적합 방지
   - 분석모델 파라미터의 증가 및 파라미터 간 복잡한 관계 증가로 과적합 발생 가능성 ㅇ
   - 정확도(신뢰도) 저하될 수 ㅇ
3. 해석력 확보
   - 차원이 작은 간단한 분석모델일수록 이해 쉽고 해석 쉬워짐
4. 차원의 저주
   - 알고리즘 통한 학습 위해 차원 증가하면서 학습데이터 수가 차원 수보다 적어져서 성능 저하됨
   - 차원 줄이거나 데이터 수 늘려야 함



**차원 축소 방법**

1. 요인 분석

   - 다수의 변수들 간 상관관계 분석해서 공통차원 축약하는 통계분석
   - 변수 특성 파악 : 관련된 변수들이 군집으로서 요인 간 상호 동립성 파악이 용이해짐
   - 독립변수, 종속변수 개념이 없음
   - 주성분 분석, 공통요인 분석 특이값 분해(SVD), 음수미포함 행렬분해(NMF) 등
   - 공통 요인 분석 : 변수들이 가지고 있는 공통분산만을 이용해서 공통요인만 추출

   1. 주성분 분석
      - 특성을 설명할 수 있는 하나 OR 복수 개의 특징(주성분) 찾는 것
      - 서로 연관성 있는 고차원공간의 데이터를 선형연관성이 없는 저차원으로 변환하는 과정(직교변환)
      - 2차원 좌표평면에 N개 점데이터들이 타원형으로 분포 > 분포 특성을 2개의 벡터로 설명
      - 어떠한 사전적 분포 가정의 요구 없음
      - 가장 큰 분산의 방향들이 주요 중심 관심으로 가정
      - 선형결합으로만 고려
      - 서로 상관 있을 때만 가능
      - 스케일에 대한 영향 큼 > 스케일링 필수
   2. 특이값 분해(SVD)
      - M = U∑Vt(전치)
      - U : 직교행렬
      - ∑ : m × n 대각행렬(행렬 대각성분 제외한 나머지 행렬 원소의 값이 모두 0)
      - Vt : n × n 직교행렬(열벡터가 독립)
      - 기존 A 정보를 SVD에 의해 3개의 행렬로 분해 > 적당한 k값(특이값)만을 이용해서 A랑 비슷한 정보력 가지는 차원 만들기
      - 몇 개의 특이값을 가지고도 충분히 유용한 정보를 유지할 수 있는 차원을 생성
   3. 음수 미포함 행렬분해(NMF)
      - 음수를 포함하지 않은 행렬 V를 음수를 포함하지 않은 두 행렬의 곱으로 분해
      - W의 열개수와 H의 행개수가 WH = V가 되도록
      - 이 둘의 오차를 U라고 하면 V = WH + U (U는 양수 음수 될 수 있음)
      - W, H의 크기가 V보다 작아서 저장하거나 다루기 좋음(곱해지는 행렬은 훨씬 적은 차원 가짐)



**파생변수 생성**

> 파생변수 : 기존 변수 조합해서 새로운 변수 만들어내기
>
> 데이터마트 > 요약변수와 파생변수들의 모임

1. 파생변수
   - 특정 조건 만족하거나 특정 함수에 의해 값을 만들어 의미부여하는 함수
   - 매우 주관적이어서 논리적 타당성 갖춰야
   - 특정상황에만 유의미하지 않게 대표성을 나타내게 해야 함
2. 요약변수
   - 수집된 정보를 분석에 맞게 종합한 변수(aggregate)
   - 데이터마트에서 가장 기본적인 변수
   - 재활용성 높음(많은 분석 모델에서 공통으로 사용 ㅇ)
3. 요약변수 VS 파생변수
   1. 요약변수 처리 시 유의점
      - 처리 방법에 따라 결측치의 처리 및 이상값 처리에 유의해야
      - 연속형 변수의 구간화 적용과 고정된 구간화를 통한 의미 파악 시 정구간이 아닌 의미있는 구간 찾아야
   2. 파생변수 생성 방법
      - 한 값으로부터 특징 추출
      - 레코드 내의 값 결합
      - 다른 테이블의 부가적 정보 결합
      - 시간 종속적인 데이터 선택
      - 요약



**변수 변환**

> 데이터를 분석하기 좋은 형태로 바꿈
>
> 전처리 과정 중 하나



**변수 변환 방법**

1. 범주형 변환
   - 분석결과의 명료성 및 정확성 배가시키기 위해
2. 정규화
   - 스케일이 심하게 차이나는 경우 상대적 특성이 반영된 데이터로 변환하는 게 필요
   - 일반 정규화
   - 최소-최대 정규화
     - 가장 일반적
     - 최소값 0, 최대값 1
     - (X - Min) / (Max - Min)
     - 이상치 영향을 많이 받음
   - Z - score 정규화
     - 이상치 문제 피하는 정규화
     - Z = (X - μ) / σ
     - 데이터 값이 평균과 일치하면 0으로 정규화
     - 평균보다 작으면 음수, 크면 양수
     - 표준편차가 크면 정규화되는 값이 0에 가까워짐
   - 로그변환
     - 로그를 취하면 분포가 정규 분포에 가까워지는 경우에
     - X ~ ln(X)
     - 데이터 형태가 우측으로 치우친 경우
   - 역수 변환
     - X ~ 1/X
     - 극단적인 우측으로 치우친 경우
   - 지수변환
     - X ~ Xn
     - 좌측으로 치우친 경우
   - 제곱근변환
     - X ~ √X
     - 우측으로 약간 치우친 경우
   - 분포형태별 정규분포 변환
     - 정규성 검정은 눈으로 확인할 수 있지만 샤피로테스트, 큐큐플롯(Q-Q Plot) 이용해서 확인 ㅇ
     - 적당한 변수변환식 사용해서 정규분포 형태로 변환 ㅇ



**불균형 데이터 처리**

> 데이터 양에 차이가 큰 경우 클래스 불균형 있다고 함

- 문제점

  - 클래스 비율이 차이가 너무 나면 우세한 클래스를 택하는  모형의 정확도가 높아지므로 성능판별 어려워짐

  - 정확도가 높아도 데이터 개수가 적은 클래스 재현율이 급격히 작아짐

  - | TP   | FP   |
    | ---- | ---- |
    | FN   | TN   |

  - 정확도 : 전체 중에 맞은 확률

  - 재현율 : 사실이 참인 것 중 실험 결과가 참인 확률



**불균형 데이터 처리 방법**

1. 가중치 균형방법
   - 손실 계산할 때 특정 클래스의 데이터에 더 큰 손실값을 갖도록
   - 각 클래스별 특정 비율로 가중치 줘서 분석하거나 결과 도출
   - 고정 비율 이용
     - 클래스 비율에 따라 가중치
     - 적은 샘플 수를 가진 클래스를 전체 손실에 동일하게 기여하도록
     - 클래스 비율이 1 : 5면 가중치를 5 : 1로 줌
   - 최적 비율 이용
     - 분야와 최종 성능 고려해서 가중치 비율이 최적 세팅 찾으면서 가중치 찾아감
2. 언더샘플링과 오버샘플링
   - 언더샘플링
     - 대표클래스의 일부만 선택, 소수클래스는 최대한 많은 데이터 사용
     - 대표클래스는 대표성 있어야
   - 오버샘플링
     - 소수클래스 복사본 만들어서 대표클래스 수만큼 데이터 만드는 것
   - 데이터 비율 맞추면 정밀도 향상



---



## 3. 데이터 탐색의 기초



**EDA(탐색적 데이터 분석)**

- 데이터 분석 전 자료를 직관적인 방법으로 통찰하는 과정
- 필요성
  - 내재된 잠재적 문제에 대해 인식하고 해결안 도출
  - 문제정의 단계에서 인지 못한 새로운 양상, 패턴 발견 가능
- 분석과정 및 절차
  - 목적과 변수가 뭔지
  - 데이터의 문제성 확인(결측치 유무, 이상치 유무, head, tail부분 확인)
  - 개별 속성값이 예상한 범위 분포를 가지는지
  - 관계속성 확인 절차



**이상치 검출**

> 이상치가 왜 발생했는지 의미를 파악하는 게 중요

1. 개별 데이터 관찰

   - 패턴이 뒤에서 나타날 수도 있으므로 뒤나 무작위로 표본을 추출해서 관찰

2. 통계값 활용

   - 요약 통계지표 사용 가능
   - 중심을 알고 싶으면 평균, 중앙값, 최빈값 사용
   - 분산도를 알고 싶으면 범위, 분산 사용

   1. IQR 방법(사분위범위 이용한 이상치 제거)
      - 최대값 = 3사분위수 + 1.5 * IQR
      - 최소값 = 1사분위수 - 1.5 * IQR
   2. 정규분포를 활용(평균과 분산 이용한 이상치 제거)

3. 시각화 활용

   - 확률밀도함수, 히스토그램, 점플롯, 워드 클라우드, 시계열 차트, 지도 등

4. 머신러닝 기법 활용

   - K-means 통해 확인 가능



**변수 간 상관성 분석**

> 두 변수 간 어떤 선형적 관계를 가지고 있는지 분석
>
> 상관관계 : 두 변수 간 관계의 강도

1. 단순상관분석 : 단순히 두 개의 변수가 어느정도 강한 관계에 있는가
2. 다중상관분석 : 3개 이상 변수 간 관계강도 측정
   - 편상관관계분석 : 다중상관분석에서 다른 변수와의 관계 고정하고 두 변수 관계강도 측정



**상관분석 기본 가정**

1. 선형성 : 두 관계가 직선적인지  > 산점도를 통해 알 수 있음
2. 동변량성(등분산성) : x값에 관계없이 y의 흩어진 정도가 같은 것
   - 산포도가 특정 구간에 상관없이 퍼진 정도가 일정할 때 동변량성 띈다고 함
3. 두 변인의 정규분포성 : 두 변인의 측정치 분포가 모집단에서 모두 정규분포를 이루는
4. 무선독립표본 : 표본 뽑을 때 표본대상이 확률적으로 선정된다는 것



**상관분석 방법**

1. 피어슨 상관계수
   - x와 y 간의 선형 상관관계를 계량화한 수치
   - +1과 -1 사이의 값 가짐
   - +1은 완벽한 양의 선형 관계, 0은 상관관계 없음 -1은 완벽한 음의 선형 상관관계
2. 스피어만 상관계수
   - 서열자료인 경우, 데이터를 작은 것부터 차례로 순위를 매겨서 서열 순서로 바꾼 뒤 순위 이용해서 상관계수 
   - 두 변수 간 연관 관계 있는지 없는지 알려줌
   - 이상점 있거나 표본크기 작을 때 유용
   - 두 변수 차이가 클수록 스피어만 상관계수 값은 커짐
   - 1에 가까울수록 단조적 상관성(커지면 같이 증가)
   - 0에 가까우면 상관없 없음
   - 선형관계의 경우에는 직선 형태로 모형화 가능
   - 직선이 아니고 곡선 > 일정한 비율로 변화되는 게 아니다



**중심화 경향 기초통계량**

1. 산술평균
   - 그냥 일반적인 평균
2. 기하평균
   - n개 자료에 대해 관측치 곱한 후 n 제곱근으로 
3. 조화평균
   - 역수의 산술평균을 구한 후 다시 역수
   - 각자료가 동일하면 조화평균, 산술평균값과 기하평균값은 같음
   - 하지만 자료가 서로 다르면 조화 <= 기하 <= 산술 순서
4. 중앙값
   - 만약 n이 짝수이면 n/2번째와 n/2+1번째 자료의 평균을 중앙값으로
5. 최빈값
   - 질적자료, 양적자료 모두 사용
6. 분위수



**산포도(분산도)**

> 자료의 퍼짐 정도

1. 분산, 표준편차
   - 분산 : 평균을 중심으로 밀집되거나 퍼짐 정도 나타냄
     - 개개의 자료값에 대한 정보 반영
     - 특이점에 큰 영향 받음
   - 표준편차 : 분산의 제곱근
2. 범위
   - 최대값과 최소값 차이를 나타냄
   - 동일한 범위 갖더라고 자료의 분포모양은 다를 수 ㅇ
3. 평균 절대 편차(평균 편차(MAD), 절대 편차(MD))
   - 관측값에서 평균 빼고, 그 차이값에 절대값하고 , 그 값들 더해서 전체 개수 나눠준 거
   - 개개 자료값에 대한 정보 반영
   - 이상치 영향 적게 받음(범위보다)
   - 수리적으로 다루기 부적절(절대값으로 하기 때문에)
   - 평균 편차 클수록 자료는 폭넓게 분포
4. 사분위범위
   - 사분위범위 : Q3 - Q1
   - Q1 = (N+1) * (1/4)
   - 최대값 : Q3 + 1.5 * IQR
   - 최소값 : Q1 - 1.5 * IQR
5. 변동계수(CV)
   - 평균 중심으로 한 상대적인 산포의 척도
   - 측정 단위 같지만 평균에 차이 크게 보일 때 척도 비교하는 데 많이 사용
   - 클수록 상대적으로 넓게 분포
   - 표준편차/평균



**자료의 분포형태**

1. 왜도

   - 어느 한쪽으로 분포가 치우친 정도

   - 오른쪽으로 길면 양의 값, 왼쪽으로 길면 음의 값

   - | 음수 | 왼쪽으로 긴   | 평균 < 중앙값 < 최빈값 |
     | ---- | ------------- | ---------------------- |
     | 0    | 좌우 대칭     | 평균 = 중앙값 = 최빈값 |
     | 양수 | 오른쪽으로 긴 | 평균 > 중앙값 > 최빈값 |

   - 피어슨의 비대칭 계수

     - Cs = 3 * (평균 - 중앙값) / 표준편차
     - 0보다 크면 왼쪽으로 치우침, 오른쪽으로 긴 꼬리 > 정적편포
     - 0보다 작으면 오른쪽으로 치우침, 왼쪽으로 긴 고리 > 부적편포

2. 첨도

   - 분포의 뾰족한 정도
   - 3미만이면 평평, 3이면 정규분포, 3초과면 뾰족



**통계적 시각화 도구**

1. 도수분포표
   - 수집된 자료를 적절한 계급에 의해 분류해서 정리한 표
   - 도수 : 각 범주별 빈도
   - 상대도수 : 도수 / 전체자료 수
2. 히스토그램
3. 막대그래프
   - 도수 or 상대도수 그림으로 표현
4. 파이차트
5. 산점도
6. 줄기 잎 그림
   - 표와 그래프의 혼합된 방법
7. 상자수염 그림
   - 자료로부터 얻어낸 통계량(5가지 요약 수치) 가지고 그림
     - 최소값, Q1, Q2, Q3, 최대값



---



## 4. 고급 데이터 탐색



**다변량 데이터 탐색**

- 종속변수와 독립변수 사이의 인과관계
  1. 다중회귀
     - 독립변수 2개 이상인 회귀모형(각 독립변수는 종속변수와 선형관계에 있음을 가정)
     - 다중회귀분석을 통해 편이를 제거할 수 있음
     - 오차항의 평균은 0이라고 가정
     - 모수에 대해 선형이라고 가정
     - 오차항은 정규분포를 따르며 각 독립변수 역시 독립인 관계
     - 최소자승법을 이용해서 결과 도출
  2. 로지스틱 회귀
     - 사건의 발생 가능성을 예측하는 데 사용
     - 종속변수가 이항형 문제를 지칭할 때 사용
     - 이항형인 데이터에 적용했을 때 종속 변수 y의 결과가 0, 1로 제한
     - 종속 변수가 이진적이라서 조건부 확률의 분포가 정규분포가 아닌 이항 분포를 따름(시그모이드 함수)
  3. 분산분석(ANOVA)
     - 3개 이상 표본들의 차이를 표본평균 간 분산과 표본 내 관측치 간 분산을 비교해서 가설 검정
     - 일원분산분석(One way ANOVA) : 단 하나의 인자에 근거해서 여러 수준으로 나눠지는 분석
       - 종속변수와 정수값을 갖는 요인변수가 각 하나여야 하고 요인변수가 정의되어야
       - 독립변수에 의해 종속변수에 대한 평균치의 차이를 검정하는 데 이용
  4. 다변량 분석분석
     - 이원분산분석(Two way ANOVA) : 측정형 변수, 종속 변수가 2개 이상인 분산분석
       - 독립변인의 수가 두개 (일원분산분석과 다름)



**변수 축약**

1. 주성분분석(PCA)
   - 다변량자료에서 존재하는 비정규성이나 이상치 발견하기 위해 새로운 변수를 구하는 것
2. 요인분석
   - 다수 변수들의 상관관계 분석해서 공통차원들을 통해 축약해나감
   - 정보손실 최소화하면서 소수의 요인으로 축약
   - 독립변수와 종속변수 개념 없음
3. 정준상관분석
   - 두 변수집단 간 연관성을 각 변수집단에 속한 변수들의 선형결합의 상관계수 이용해서 분석
   - 인과성이 없음



**개체유도**

> 개체들 특성 측정한 변수들의 상관관계 이용해서 유사한 개체 분류하는 방법

1. 군집분석
   - 군집 간 거리에 대한 정의가 가장 중요 > 거리 정의에 따라 유사성에 대한 척도 형성
   - 계층적 방법 : 가까운 애들끼리 묶거나 먼 애들을 분리하거나
   - 한 번 병합된 개체는 다시 분리되지 않음
   - 비계층적 방법(최적분화 방법) : 다변량 자료의 산포를 나타내는 여러 가지 측도 이용해서 판정기준을 최적화시키는
   - 한 번 분리된 개체도 재분류될 수 있음
   - 조밀도에 의한 방법 : 특성에 따라 군집 나누기
   - 그래프를 이용하는 방법
2. 다차원 척도법(MDS)
   - 개체들 간 거리 또는 비유사성을 이용해서 개체들을 원래 차원보다 낮은 차원의 공간상에 위치시켜
   - 구조나 관계를 쉽게 파악하고자
3. 판별 분석
   - 2개 이상의 그룹으로 나눠진 개체에 대해 특성을 측정하고 새로운 개체를 분류
   - 로지스틱 판별분석  : 분류하는 도구(판별식)을 로지스틱 회귀분석을 이용해서 분류



**비정형 데이터**

- 정형 데이터에 비해 저장 공간 넓음
- 분석이 용이하지 않음



**비정형 데이터 분석**

1. 데이터 마이닝

   1. 자동적으로 통계적 규칙이나 패턴 분석해서 가치있는 정보 추출
   2. OLAP, SOM, 신경망, 전문가 시스템 등의 기술적인 방법론 쓰임

   - 분류 : 일정한 집단에 대한 특정 정의를 통해 분류, 구분 추론
   - 군집화 : 미리 정의된 특성에 대한 정보를 가지지 않음
   - 연관성 : 동시에 발생한 사건 간의 관계 정의
   - 연속성 : 특정 기간에 걸쳐 발생하는 관계
   - 예측
   - 단점 : 자료에 의존하기 때문에 오류 범할 수 있음

2. 텍스트 마이닝

   - 자연어 처리 방식을 이용 > 데이터의 숨겨진 의미 발견

3. 오피니언 마이닝(감정 분석)

   - 사람들의 주관적 의견을 통계, 수치화해서 객관적 정보로 바꾸는 분석기술
   - 텍스트 마이닝은 문장 내 주제 파악
   - 오피니언 마이닝은 감정, 뉘앙스, 태도 등을 판별
   - 중립, 긍정, 부정으로 분류

4. 웹 마이닝

   - 웹 자원으로부터 의미있는 패턴, 추세 등 도출
   - 웹구조 마이닝 : 구조적 요약정보 추출
   - 웹내용 마이닝 : 페이지로부터 의미있는 내용 추출
   - 웹사용 마이닝 : 웹상의 사용자의 행동 등 패턴



---



## 5. 기술통계



**기술통계**

> 분석에 필요한 데이터를 요약해서 묘사, 설명

종류

- 중심화 경향
  - 데이터의 물리적 상대적 위치에 대한 정리 요약
- 분산도 경향
  - 흩어진 정도에 대한 기술 및 요약
- 자료의 분포형태
  - 대칭인지 치우쳐있는지에 대한 기술 및 요약



**전수조사와 표본조사**

- 전수조사
  - 모집단 전체를 대상으로 조사
- 표본조사
  - 표본을 추출해서 표본을 대상으로 조사



**표본추출 오차**

- 과잉 대표
  - 중복선택 등의 원인으로 모집단 반족, 중복된 데이터만으로 규정되는 현상
- 최소 대표
  - 대표성을 나타낼 표본이 아닌 다른 데이터가 표본이 되는 현상
  - 표본추출시 표본의 크기보다는 대표성을 가지는 표본을 추출하는 게 중요



**표본추출 기법**

> 사전에 일정한 추출확률이 주어지는 표본추출법
>
> 모든 표본들의 추출확률을 사전에 알 수 있음
>
> 추정량의 통계적 정확도를 확률적으로 나타낼 수 있음

1. 단순무작위 추출

   - 무작위 추출하고, 독립적 선택으로 편향성 제거해서 난수를 이용
   - 추출 모집단에 대해 사전지식이 많지 않은 경우 시행

2. 계통추출

   - 추출간격을 설정해서 간격 사이에서 무작위로 추출

3. 층화추출

   - 모집단을 서로 겹치지 않게 여러 층으로 나눠서 분할된 층별로 배정된 표본을 단순 임의 추출법에 따라 추출

   - 집단별 분석 or 특성치의 효율적인 추정이 필요한 경우 시행

   - 추정의 정도 높일 수 ㅇ

   - 층화변수 : 추출단위가 어느 층에 속하는지 구분하기 위해 기준으로 사용되는 변수

     - 양적 층화변수 : 경계점을 나누는 방법 필요
       - 층의 최적경계점
         1. n개 층으로 나누려면  n-1개의 경계점 결정해야
         2. 추정값의 분산을 최소화할 수 있도록 경계점 결정
     - 질적 층화변수 : 변수값에 따라 층 구분

   - 표본의 배분

     - 추출단위 수가 많으면 크게 늘리고
     - 변동의 정도가 커지면 크게 늘리고
     - 추출단위를 조사하는데 드는 비용이 증가하면 줄인다

     - | 비례배분법   | 추출단위 수에 비례해서 표본크기 배분<br />비용은 고려하지 않고 층의 크기만고려<br />여론조사, 의식조사 등에 많이 활용 |
       | ------------ | ------------------------------------------------------------ |
       | 네이만배분법 | 각 층 크기와 층별 변동 정도를 동시에 고려<br />변동이 큰 층에 대해서는 상대적으로 많은 표본 배정 |
       | 최적배분법   | 분산 최소화시키거나 주어진 분산의 범위 하에서 비용을 최소화  |

4. 군집추출

   - 차이가 없는 여러 개 군집으로 나눠서 단위의 일보 또는 전체에 대한 분석 시행
   - 구체적인 추출 방법론을 정하기 어려운 경우 편함
   - 단순 임의추출에 비해 표본 오차가 증대할 가능성 ㅇ



**비확률 표본추출 기법**

> 표본에 추출될 확률을 객관적으로 나타낼 수 없는 표본추출법
>
> 모집단을 정확하게 규정지을 수 없는 경우, 표본오차가 큰 문제가 되지 않는 경우, 새로운 개념에 대한 탐색적 연구 등에 쓰임

1. 간편추출법(편의추출법)
   - 응답자 선정할 때 조사원 개인의 자의적 판단에 따라 간편한 방법으로 표본추출
2. 판단추출법
   - 조사자가 나름의 지식과 경험에 의해 모집단을 가장 잘 대표한다고 여겨지는 표본을 주관적으로 선정
   - 추정치의 정확성에 대해 객관적 평가 불가능
   - 표본 크기가 작으면 오차를 좌우하는 요인은 추정량의 분산이 될 수 ㅇ
3. 할당추출법
   - 조사목적과 밀접하게 관련되어 있는 조사대상자의 변수값에 따라 모집단을 부분집단으로 나누고, 그 부분집단별 구성비율과 표본의 부분집단별 구성비율이 유사하도록 표본 선정
   - 비용 적고 쉬워서 단기간에 조사해야 하는 경우 사용
4. 눈덩이추출법
   - 접근 어렵거나 추출틀의 작성이 곤란한 특정한 집단에서 사용
   - 해당 집단에 속하는 걸 사전에 알고 있는 사람들을 대상으로, 다른 사람들을 소개받아서 진행
   - 이렇게 하면 표본이 눈덩이처럼 커짐



**확률분포**

> 기술통계 : 데이터 요약, 묘사, 설명
>
> 추측통계(추론통계) : 내포된 정보를 이용해서 모집단에 대한 과학적인 추론 



**확률**

- 통계적 현상 : 고유의 법칙성을 찾아내는 것이 가능한 현상
- 확률 실험 : 같은 조건 아래에서 반복 가능
  - 시행 결과는 매번 우연적으로 변하므로 예측 불가능하지만, 가능한 모든 결과의 집합 알 수 ㅇ
  - 낱낱의 결과는 불규칙하게 나타나지만, 반복의 수를 늘리면 어떤 규칙성이 나타나는 특징 가질 수 ㅇ
- 경우의 수
  - 합의 법칙 
  - 곱의 법칙
  - 순열 : 서로 다른 n개 원소에서 r개를 중복없이 순서 고려해서 선택하는 경우의 수
  - 조합 : 서로 다른 n개 원소에서 r개를 중복없이 순서를 고려하지 않고 선택하는 경우의 수

1. 확률

   - 통게적 현상의 확실함의 정도를 나타내는 척도
   - 수학적 확률 
   - 통계적 확률 
     - 일어날 가능성이 동일한 경우가 많지 않아서 수학적 확률로 구할 수 없는 경우가 대부분
     - 이럴 때 사건이 일어나는 확률을 상대도수에 의해 추정
     - n회의 시행에서 r회 일어나면 > 상대도수는 r/n >> 통계적 확률

2. 사건

   - 동일한 상태로 여러 차례 반복할 수 있는 실험이나 관측 > 시행
   - 시행의 결과로서 나타나는 것 > 사건
   - 개별적으로 발생한 결과일수도, 몇 가지의 복합된 결과의 집합이 될 수도
   - 어떤 사건의 확률은 각 결과의 발생 확률의 합으로 나타냄

3. 표본공간

   - 모든 발생 가능한 실험결과들의 집합
   - 표본공간 자체는 전사건
   - 아무것도 포함하지 않은 사건은 공사건
   - 하나의 결과를 포함하는 사건은 근원사건

4. 확률의 기본성질

   1. 0 <= p(근원사건(a)) : 어떤 사건 a가 발생할 확률은 항상 0이다
   2. p(전공간(s)) = 1 : 표본공간 s사건이 발생할 확률은 1이다
   3. 서로 독립적인 사건의 경우는 각 사건의 발생 확률을 더한다
   4. Ai가 Aj의 부분집합이면 Ai가 발생할 확류은 Aj가 발생할 확률보다 작거나 같다

5. 조건부 확률

6. 결합 확률(확률의 곱셈)

   - 사건 두 개가 동시에 발생하는 확률 > 곱셈 법칙
   - 사건 두 개가 서로 독립이면 P(A) X P(B) = P(A∩B)

7. 총확률정리

   - 사건 B의 확률을 K개의 조건부 확률을 이용해서 구하기

8. 베이지안 정리

   - 총확률정리 이용해서 계산하면 베이지안 법칙을 이용해서 표본공간을 분할하는 K개의 상호 배타적인 사건에 대한 사후확률을 구할 수 ㅇ

   1. 직장 남성 30%가 기관지에 이상있다
   2. 실제 검사하였을 때 검사결과가 90%가 이상이 있다고 나온다
   3. 기관지에 이상이 없는 경우에도 이상반응이 나올 수 있는 확률은 10%
   4. 임의의 직장 남성이 검사했을 때 이상반응이 나타났지만 실제론 이상이 없을 확률
   5. A1는 기관지에 이상 있을 사건, A2는 이상 없을 사건, B는 검사결과 이상반응이 나타날 사건
   6. P(A1) = 0.3, P(A2) = 0.7, P(B|A1) = 0.9, P(B|A2) = 0.1
   7. P(B) = P(B|A1)P(A1) + P(B|A2)P(A2) = 0.9*0.3+0.1\*0.7 = 0.34
   8. 검사결과 이상이 있는 것으로 나타난 사람에게 이상이 없는 사후확률
   9. \>> P(A2|B) = P(B|A2)P(A2)/P(B)



