---



## 2. 분석모형 개선



**과적합 방지**

1. 모델의 낮은 복잡도
   - 정규화, 드롭아웃 등을 활용해서 과적합 방지
   - 하이퍼파라미터(과적합의 위험을 줄이기 위해 제약을 가하는 규제의 양을 결정, 상수값) > 큰 값을 지정할수록 복잡도 낮음
   - 드롭아웃 : 은닉층의 뉴런을 임의로 삭제하면서 학습
     - 훈련에는 삭제할 뉴런 선택, 테스트에는 뉴런에 신호 전달하고 훈련 때 삭제한 비율 곱해서 전달
2. 가중치 감소
   - 큰 가중치에 패널티 > 가중치 절대값 작게
   - L1 규제
     - L2규제의 가중치 제곱을 절대값으로 바꿈
     - 절대값인 L1 노름을 추가로 적용 > 희소한 특성 벡터 > 특성 가중치를 0으로
   - L2 규제
     - L2 노름(벡터의 크기를 측정하는 방법)의 제곱을 더한 패널티 부여 > 가중치 값을 모델에 비해 작게 만듦
     - 중심점을 찾아서 큰 가중치를 제한 > 람다로 규제 강도 크게 > 가중치는 0에 가까워짐
     - 회귀모델에서 L2규제 적용한 게 릿지모델
3. 편향-분산 트레이드오프
   - 과적합과 과소적합 사이의 절충점을 찾음



**매개변수 최적화**

> 손실 함수의 값을 최대한 낮추는 매개변수 찾는 게 목표 > 매개변수 최적화

1. 확률적 경사 하강법

   - 매개변수에 대한 손실함수의 기울기 이용 
   - 조금씩 아래로 내려가보면 손실함수가 가장 작은 지점에 도달하도록
   - 랜덤으로 선택한 하나의 데이터로만 계산 > 단순하고 명확한 구조
   - (0,0)까지 지그재그로 이동 > 비효율적인 움직임

2. 모멘텀

   - 모멘텀 = 운동량
   - 확률적 경사 하강법에 속도 개념인 기울기 방향으로 힘을 받는 관성 물리법칙 적용
   - ~모양

3. AdaGrad

   - 학습률이 작으면 학습 시간이 길어지고, 커지면 발산해서 학습이 제대로 안됨
   - 개별 매개변수에 학습률 조정하면서 학습 진행
   - 처음엔 크게 학습하다가 최적점에 가까울수록 학습률 줄임
   - L모양

4. Adam

   - 모멘텀과 AdaGrad 합친
   - 3가지 초매개변수 설정(학습률, 일차 모멘텀 계수, 이차 모멘텀 계수)
   - 약간 U자 모양

5. 초매개변수(하이퍼파라미터) 최적화

   - 사람이 직접 설정해줘야 하는 매개변수
   - 뉴런수, 배치크기, 학습률, 은닉층 개수

   1. 학습률
      - 기울기 방향으로 얼마나 빠르게 이동할지 결정
   2. 미니배치 크기
      - 배치 : 경사 하강법 1회에 사용되는 데이터 묶음
      - 전체 학습 데이터를 주어진 배치 크기로 나눠
   3. 훈련 반복 횟수(Epoch)
      - 전체 훈련데이터 셋이 신경망을 통과한 횟수
      - 1Epoch는 1회 학습으로 통과됐다는 뜻
      - 학습의 조기종료를 결정하는 변수
   4. 이터레이션(Iteration)
      - 하나의 미니배치를 학습할 때 1Iteration
      - 미니배치 수와 이터레이션 개수는 동일
   5. 은닉층 개수
      - 은닉층 수 많아질수록 특정 훈련데이터에 더 최저고하시킬 수 ㅇ
      - 모든 은닉층들이 뉴런 개수 동일하게 유지하는 게 B
      - 첫 번째 은닉층에 있는 뉴런 개수가 입력층에 있는 뉴런 개수보다 큰 게 효과적



**분석모형 융합**

1. 앙상블 학습
   - 치우침이 있는 여러 모형의 평균을 취할 시 균형적인 평균을 얻음
   - 변동성 및 과적합 여지 줄어듦
   - 배깅 : 데이터 샘플링, 모델링 후 전체 결합해서 결과 평균
   - 부스팅 : 순서대로 모델 진행
   - 랜덤포레스트 : 배깅 적용한 의사결정나무
2. 결합분석모형
   - 두 종류 이상의 결과변수를 동시에 분석할 수 있는 방법



**최종모형 선정**

1. 회귀모형에 대한 주요 성능평가지표
   1. SSE
      - 실제값과 예측값 차이를 제곱해서 합
   2. 결정계수 R2
      - 저갛ㅂ한 회귀모형이 실제값을 얼마나 잘 적합하는 지에 대한 비율
   3. MAE
      - 실제값과 예측값의 차이의 절대값을 합한 평균
   4. MAPE
      - MAE계산 시 실제값에 대한 상대적 비율 고려
2. 분류모형에 대한 주요 성능평가지표
   - 특이도
     - 실제 음성 중 예측으로 맞춘 음성 수
     - TN / (TN + FP)
   - 정밀도
     - 예측으로 양성 중 실제 양성 수
     - TP / (TP + FP)
   - 재현율
     - 민감도
     - 실제 양성 중 예측으로 맞춘 양성 수
     - TP / (TP + FN)
   - 정확도
     - 전체 수 중 양성과 음성을 맞춘 수
     - (TP + TN) / (TP + TN + FP + FN)
3. 비지도학습 모형에 대한 주요 성능평가지표
   1. 군집분석
      - 군집 간 분산과 군집 내 분산
      - 군집 간 거리, 군집의 지름, 군집의 분산 등을 고려
   2. 연관분석