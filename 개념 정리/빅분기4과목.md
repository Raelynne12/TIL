## 1. 분석모형 평가



**지도학습-분류모델 평가 지표**

> 분석모형의 답과 실제 답과의 관계 오차행렬을 통해 평가

|          |       | 실제답 |       |
| -------- | ----- | ------ | ----- |
|          |       | True   | False |
| 예측결과 | True  | TP     | FP    |
|          | False | FN     | TN    |

- 오차행렬
  - 훈련을 통한 예측 성능을 측정하기 위해 예측값과 실제값 비교하기 위한 표
- 정확도
  - TP + TN / 전체
- 정밀도
  - 긍정으로 예측한 대상 중 실제로 긍정적인 
  - TP / (TP + FP)
- 재현도
  - 실제 긍정적인 애들 중 긍정으로 예측한 
  - TP / (TP + FN)
- F1 Score
  - 정밀도와 재현율 결합한 조화평균 지표
  - 값 클수록 모형 정확함
  - 2 × precision*recall / precision + recall
- ROC
  - FRR(실제로 부정적인 애들 중 긍정으로 예측한)가 변할 때 민감도 TPR(실제로 그정적인 애들 중 긍정으로 예측한)이 어떻게 변하는지 나타내는 곡선
  - 임계값을 1 ~ 0 범주 이내 값으로 조정하면서 FPR에 따른 TPR을 계산하면서 곡선
    - 0.5보다 위에 위치할 경우 기본 모델보다 성능 나음
- AUC
  - ROC 곡선의 하단 면적
  - 곡선이 직선에서 멀어질수록 성능 더 B



**지도학습 - 회귀모델 평가지표**

> 실제값과 회귀 예측값의 차이를 기반으로 성능지표 수립, 활용

1. SSE
   - 실제값과 예측값의 차이를 제곱해서 합
2. MSE
   - 실제값과 예츨값의 차이의 제곱에 대한 평균 >> 평균제곱 오차
3. RMSE
   - MSE에 루트 >> 평균제곱근 오차
4. MAE
   - 실제값과 예측값의 차이의 절대값을 합한 평균
5. 결정계수 R2
   - 회귀모형이 실제값에 대해 얼마나 잘 적합하는 지에 대한 비율
6. Adjusted R2
   - 다변량 회귀분석에서 독립변수 많아질수록 결정계수 높아짐 
   - 보완하기 위해 표본크기(N)과 독립변수 개수(P)를 추가적으로 고려
   - 결정계수 값의 증가도를 보정
7. MSPE
   - MSE를 퍼센트로 변환
8. MAPE
   - MAE를 퍼센트로 변환
9. RMSLE
   - RMSE에 로그를 취한 값
   - 이상치에 덜 민감
10. AIC
    - 최대 우도에 독립변수 개수에 대한 손실분 반영하는 목적
    - 모형과 데이터 확률 분포 차이 측정
    - 낮을수록 적합도 높아짐
11. BIC
    - 변수의 개수가 많을수록 AIC보다 더 패널티 가하는 성격



**비지도학습 - 군집분석 평가 지표**

> 라벨링이 없어서 성능평가가 어려움 > 군집분석에 한해 성능 평가 지표 참고

1. 실루엣 계수
   - a(i) > i번째 개체와 같은 군집에 속한 요소들 간 거리 평균
   - b(i) > i번째 개체가 속한 군집과 가장 가까운 이웃군집을 선택 계산한 값
   - a(i)가 0이면 하나의 군집에 모든 개체들 붙어있음
   - 0.5보다 크면 적절한 군집 모델
2. Dunn Index
   - 군집 간 거리의 최소값 > 분자
   - 군집 내 요소간 거리 최대값 > 분모
   - 군집 간 거리는 멀수록, 군집 내 분산은 작을수록 b
   - 클수록 b



**분석모형 진단**

1. 정규성 가정

   - 통계적 검정, 회귀 분석 등 분석 진행 전 데이터가 정규분포 따르는지 검정 > 데이터 자체 정규성 확인

   1. 중심극한 정리
      - 동일한 확률분포를 가진 독립 확률변수 n개의 평균 분포는 n이 적당히 크다면 정규분포에 가까워짐
      - 표본분포 평균 = 모집단의 모평균
      - 표준편차 = 모집단의 모표준편차를 표본크기의 제곱근으로 나눈 것
   2. 정규성 검정 종류
      - 샤피로 - 윌크 검정 : 표본수가 2000개 미만인 데이터 셋에 적합
      - 콜모고로프 스미르노프 검정 : 표본수가 2000개 초과인 데이터 셋에 적합
      - Q - Q 플롯 : 표본수가 소규모일 때 적합

   - 데이터 셋이 정규분포를 따른다는 귀무가설을 기각하고 대립이 채택되면 > 데이터 셋은 정규분포 따르지 않음 증명

2. 잔차 진단

   - 회귀분석에서 독립과 종속변수 관계 결정하는 최적의 회귀선은 잔차를 가장 작게 해주는 선
   - 잔차의 합은 0, 추세나 특정 패턴 x

   1. 잔차의 정규성 진단
      - 시각화도표를 통해서 정규분포와 잔차의 분포 비교
   2. 잔차의 등분산성 진단
      - 분산이 특정 패턴 없이 순서와 무관하게 일정한지 등분산성 진단
   3. 잔차의 독립성 진단
      - 잔차의 독립성 = 자기상관의 여부를 판단
      - 시점 순서대로 그래프 그리거나, 더빈-왓슨 검정으로 패턴 없으면 > 독립성 충족
      - 독립성 위배되면 > 시계열 분석 통해서 회귀분석 해야



**K - 폴드 교차검증**

> 과적합 방지하기 위해 나온 방법

- 전체 데이터 셋을 k개 서브셋으로 분리 > k-1개를 훈련데이터로, 1개는 테스트데이터로
- 테스트 셋을 중복없이 병행 진행 > 평균 > 최종적 모델의 성능 평가
- 반복횟수 증가에 따라 훈련과 평가 검증 시간이 오래 걸림
- 교차검증 기법에는 k - 폴드 교차검증, 홀드아웃 기법, 리브 - p - 아웃 교차검증, 리브 - 원 - 아웃 교차검증, 계층별 k -겹 교차검증 등
  - 홀드아웃 기법 : 훈련데이터, 검증데이터 테스트데이터를 일정 비율로 지정 > 훈련데이터 내에서 일정 부문 검증데이터를 둬서 검증 진행 / 데이터 셋 크기 작을수록 나누는 방식에 따라 성능 추정에 민감한 영향 미칠 수 ㅇ



**적합도 검정**

> 데이터가 가정된 확률에 적합하게 따르는지(분포가 특정 분포함수와 얼마나 맞는지 검정)
>
> 정규성 검정이 일반적
>
> 모집단의 분포를 정규분포로 가정하는 분석기법(t-Test, Anova, 회귀분석)
>
> 그 외 카이제곱 검정, 콜모고로프 스미르노프 검정

1. 카이제곱 검정
   - 범주형 값 k가 나와야 할 횟수의 기대값 mk와 실제 나온 횟수 xk의 차이를 이용해서 검정통계량 구함
2. 콜고로로프 스미르노프 검정(K - S Test)
   - 관측된 표본분포와 가정된 분포 사이의 적합도 검사하는 누적분포함수의 차이를 이용
   - 연속형 데이터에도 ㅇ

- p-value : 귀무가설 대신 대립가설을 선택할 시 오류를 범할 최대확률값
  - 0.05보다 크면 >> 귀무가설 채택
  - 0.05보다 작거나 같으면 >> 대립가설 채택



---



## 2. 분석모형 개선



**과적합 방지**

1. 모델의 낮은 복잡도
   - 정규화, 드롭아웃 등을 활용해서 과적합 방지
   - 하이퍼파라미터(과적합의 위험을 줄이기 위해 제약을 가하는 규제의 양을 결정, 상수값) > 큰 값을 지정할수록 복잡도 낮음
   - 드롭아웃 : 은닉층의 뉴런을 임의로 삭제하면서 학습
     - 훈련에는 삭제할 뉴런 선택, 테스트에는 뉴런에 신호 전달하고 훈련 때 삭제한 비율 곱해서 전달
2. 가중치 감소
   - 큰 가중치에 패널티 > 가중치 절대값 작게
   - L1 규제
     - L2규제의 가중치 제곱을 절대값으로 바꿈
     - 절대값인 L1 노름을 추가로 적용 > 희소한 특성 벡터 > 특성 가중치를 0으로
   - L2 규제
     - L2 노름(벡터의 크기를 측정하는 방법)의 제곱을 더한 패널티 부여 > 가중치 값을 모델에 비해 작게 만듦
     - 중심점을 찾아서 큰 가중치를 제한 > 람다로 규제 강도 크게 > 가중치는 0에 가까워짐
     - 회귀모델에서 L2규제 적용한 게 릿지모델
3. 편향-분산 트레이드오프
   - 과적합과 과소적합 사이의 절충점을 찾음



**매개변수 최적화**

> 손실 함수의 값을 최대한 낮추는 매개변수 찾는 게 목표 > 매개변수 최적화

1. 확률적 경사 하강법

   - 매개변수에 대한 손실함수의 기울기 이용 
   - 조금씩 아래로 내려가보면 손실함수가 가장 작은 지점에 도달하도록
   - 랜덤으로 선택한 하나의 데이터로만 계산 > 단순하고 명확한 구조
   - (0,0)까지 지그재그로 이동 > 비효율적인 움직임

2. 모멘텀

   - 모멘텀 = 운동량
   - 확률적 경사 하강법에 속도 개념인 기울기 방향으로 힘을 받는 관성 물리법칙 적용
   - ~모양

3. AdaGrad

   - 학습률이 작으면 학습 시간이 길어지고, 커지면 발산해서 학습이 제대로 안됨
   - 개별 매개변수에 학습률 조정하면서 학습 진행
   - 처음엔 크게 학습하다가 최적점에 가까울수록 학습률 줄임
   - L모양

4. Adam

   - 모멘텀과 AdaGrad 합친
   - 3가지 초매개변수 설정(학습률, 일차 모멘텀 계수, 이차 모멘텀 계수)
   - 약간 U자 모양

5. 초매개변수(하이퍼파라미터) 최적화

   - 사람이 직접 설정해줘야 하는 매개변수
   - 뉴런수, 배치크기, 학습률, 은닉층 개수

   1. 학습률
      - 기울기 방향으로 얼마나 빠르게 이동할지 결정
   2. 미니배치 크기
      - 배치 : 경사 하강법 1회에 사용되는 데이터 묶음
      - 전체 학습 데이터를 주어진 배치 크기로 나눠
   3. 훈련 반복 횟수(Epoch)
      - 전체 훈련데이터 셋이 신경망을 통과한 횟수
      - 1Epoch는 1회 학습으로 통과됐다는 뜻
      - 학습의 조기종료를 결정하는 변수
   4. 이터레이션(Iteration)
      - 하나의 미니배치를 학습할 때 1Iteration
      - 미니배치 수와 이터레이션 개수는 동일
   5. 은닉층 개수
      - 은닉층 수 많아질수록 특정 훈련데이터에 더 최저고하시킬 수 ㅇ
      - 모든 은닉층들이 뉴런 개수 동일하게 유지하는 게 B
      - 첫 번째 은닉층에 있는 뉴런 개수가 입력층에 있는 뉴런 개수보다 큰 게 효과적



**분석모형 융합**

1. 앙상블 학습
   - 치우침이 있는 여러 모형의 평균을 취할 시 균형적인 평균을 얻음
   - 변동성 및 과적합 여지 줄어듦
   - 배깅 : 데이터 샘플링, 모델링 후 전체 결합해서 결과 평균
   - 부스팅 : 순서대로 모델 진행
   - 랜덤포레스트 : 배깅 적용한 의사결정나무
2. 결합분석모형
   - 두 종류 이상의 결과변수를 동시에 분석할 수 있는 방법



**최종모형 선정**

1. 회귀모형에 대한 주요 성능평가지표
   1. SSE
      - 실제값과 예측값 차이를 제곱해서 합
   2. 결정계수 R2
      - 저갛ㅂ한 회귀모형이 실제값을 얼마나 잘 적합하는 지에 대한 비율
   3. MAE
      - 실제값과 예측값의 차이의 절대값을 합한 평균
   4. MAPE
      - MAE계산 시 실제값에 대한 상대적 비율 고려
2. 분류모형에 대한 주요 성능평가지표
   - 특이도
     - 실제 음성 중 예측으로 맞춘 음성 수
     - TN / (TN + FP)
   - 정밀도
     - 예측으로 양성 중 실제 양성 수
     - TP / (TP + FP)
   - 재현율
     - 민감도
     - 실제 양성 중 예측으로 맞춘 양성 수
     - TP / (TP + FN)
   - 정확도
     - 전체 수 중 양성과 음성을 맞춘 수
     - (TP + TN) / (TP + TN + FP + FN)
3. 비지도학습 모형에 대한 주요 성능평가지표
   1. 군집분석
      - 군집 간 분산과 군집 내 분산
      - 군집 간 거리, 군집의 지름, 군집의 분산 등을 고려
   2. 연관분석



---



## 3. 분석결과 해석



**분석모형 해석**

1. 회귀모델
   - 잔차
     - MAE
     - MSE
     - RMSE
     - RMSLE
   - 결정계수
     - R2
     - 수정된 R2
2. 분류모델
   - 정확도
   - 정밀도
   - 재현율
   - F1 - score
   - ROC & AUC
3. 군집분석 모델
   - 외부평가
     - 자카드지수(집한 간 유사도 측정)
     - 얼마나 유사하게 군집화가 되었는지
   - 내부평가
     - 적절한 군집 개수 설정
     - Dunn Index(클수록 b)
   - 팔꿈치 기법
     - 팔꿈치 모습을 나타내는 곳 값을 적절한 k값으로 지정
   - 실루엣 기법
     - 다른 군집이랑 떨어지고 동일 군집끼리 묶여있는
     - 0~1사이 값 (1에 가까울수록 최적화 b)
4. 연관분석 모델
   - 지지도
     - A와 B가 동시에 포함된 거래수
   - 신뢰도
     - A 구매할 때 B가 추가로 구매될 확률(조건부)
   - 향상도 : A구매할 때 B도 추가로 구매하는 지의 연관성 비율
     - 1이면 독립적 관계



**분석결과의 기여도 평가**

- ROI(투자수익률)
  - (총체적 이익 - 소요된 비용) / 소요된 비용 * 100
- 업무 효율성 향상에 대한 비율로 측정





**분석 모델별 시각화**

1. 회귀 모델
   - 히트맵
   - 산점도
2. 분류 모델
   - SVM
   - KNN : 비교시각화의 평행좌표계 (변수들과의 연관성, 그룹데이터의 경향성 파악)
   - 의사결정나무
3. 딥러닝 모델
   - 파라미터, 가중치 시각화 및 특징 차원감소 > 시각화
   - Node-link diagrams for network architectures(네트워크 구조를 위한 노드-링크 다이어그램) : node로 시각화
   - dimensional reduction & scatter plots(차원 축소, 산포도)
   - line charts for temporal metrics(측정을 위한 선도표)
   - instance-based analysis & exploration(객체 기반 분석 및 탐색)
4. 군집분석 모델
   - 산점도
5. 연관분석 모델
   - 관계시각화 기법 > 네트워크 그래프



---



## 4. 분석결과 시각화



**데이터 시각화 접근방법**

1. 통계적 그래픽 - 분포와 통계적 정보를 2차원이나 3차원 공간에 시각적으로 표현
2. 주제 지도학 - 지리적 분포와 패턴 나타내는 지도 형태로 표현



**데이터 유형**

- 범주형 : 몇 개의 범주로 나누어진 자료(숫자, 문자, 기호 등)
- 수치형 : 숫자 값을 데이터 표현

| 범주형 | 명목형 데이터 | 순서를 매길 수 없지만, 셀 수 ㅇ |
| ------ | ------------- | ------------------------------- |
|        | 순서형 데이터 | 순서 매길 수 ㅇ, 셀 수 ㅇ       |
| 수치형 | 이산형 데이터 | 셀 수 있는 형태 값(주로 정수)   |
|        | 연속형 데이터 | 연속적 구간에서 값 취함         |



**주요 용어**

1. EDA(탐색적 자료분석) : 데이터셋에 대한 주요 특징을 주로 시각적 방법 이용해서 분석
2. 차트 : 원그래프, 막대그래프, 선그래프, 면적그래프 등 데이터 특성에 따라 선택
3. 범례 : 기호나 선 등이 어떤 의미인지 설명



**데이터 시각화 방법**

- 자주 사용되는 시각적 속성 중 형태와 선 유형 속성은 이산형 데이터에만 적용 가능

- | 시간 시각화 | 막대, 누적막대, 점/선                                      |
  | ----------- | ---------------------------------------------------------- |
  | 분포 시각화 | 히스토그램, 파이차트, 도넛차트, 트리맵, 누적연속 그래프    |
  | 관계 시각화 | 산점도, 버블차트, 히트맵                                   |
  | 비교 시각화 | 히트맵, 체르노프페이스, 스타차트, 평행좌표계, 다차원척도법 |
  | 공간 시각화 | 지도 매핑                                                  |



**데이터 시각화 영역**

1. 정보 시각화
   - 방대한 양의 정보를 한 번에 사용자가 보고 이해할 수 있도록 직관적 표현 
   - 데이터 시각화는 정보를 명확히 표현하는 게 중요, 정보시각화는 큰 범위의 집합에 대한 시각적 표현방법 중요
   - 카토그램, 분기도, 개념도, 계통도(덴드로그램), 네트워크 다이어그램, 트리맵, 하이퍼볼릭 트리 등
2. 정보 디자인
   - 시각 디자인 하위영역
   - 데이터시각화, 정보시각화, 인포그래픽 모두 포괄
3. 인포그래픽
   - 설득형 메시지를 전달하기 위해 주로 사용
   - 스토리를 통해서 정보 전달하려는 경향 강함
   - 일반인을 대상으로 전달하기에 적합
   - 비주얼, 내용, 지식이 기본 요소



**시간 시각화**

- 특정 시점의 값을 표현하는 이산형, 변화하는 값을 표현하는 연속형

- | 이산형 | 막대, 누적막대, 묶은막대, 점 |
  | ------ | ---------------------------- |
  | 연속형 | 꺾은선, 계단, 추세선         |

1. 묶은막대그래프
   - 누적막대그래프처럼 두 개 이상 변수 동시에 다루지만, 변수의 누적합계나 추이를 파악하기는 어려움
2. 점그래프
   - 점의 집중 정도와 배치에 따라 흐름 파악 용이
3. 꺾은선그래프
   - 점과 점사이 연결
   - 경향성을 뚜렷하게 보여주기 위해 사용
   - 세로축 길이를 늘리거나 가로축 길이 짧게 줄이면 변화 급격
4. 계단그래프
   - 연속된 변화 표현하기에 적합, 특정 시점에서의 변화 표현하는데 b
5. 추세선
   - 급격한 변화보다는 경향성



**분포 시각화**

1. 히스토그램
   - 도수분포표와 함께
   - 누적히스토그램
2. 도넛차트
   - 면적이 아닌 길이로 데이터 값 정도 표현
   - 같은 성격이 데이터는 여러 차트를 겹쳐서 보여줄 수 ㅇ (중첩도넛차트)
3. 트리맵
   - 하위 분류를 적용해서 다시 맵 구성 ㅇ
   - 계층형/트리 구조를 가진 데이터 표현하는 데 b
4. 누적연속그래프(누적영역차트)
   - 선그래프로
   - 시간에 따라 변화하는 값 흐름 더 잘 보여줌
   - 한 집단의 경향성을 알아보기는 힘듦
   - 값 분포 표현하는 데 b



**관계 시각화**

> 변수 2개 이상 있을 때 상관관계 표현

1. 산점도
   - 양의 상관 : 오른쪽 위
   - 음의 상관 : 오른쪽 아래
2. 버블차트
   - 제3 변수값을 원 크기로 표현
3. 히트맵



**비교 시각화**

