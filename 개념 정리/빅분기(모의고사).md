## 모의고사 1회



#### 1과목



딥러닝 분석 수행 시 주로 sigmoid funcion을 activation으로 사용



**개인정보 비식별 조치에 대한 익명성 검증 방법**

- t-근접성 
  - 전체 데이터 집합의 정보 분포와 특정 정보의 분포 차이를 t 이하로 > 추론 방지
  - 민감한 정보의 분포를 낮춰서 추론 가능성 낮춤
- k-익명성
  - 특정인임을 추론할 수 있는지 > 일정 확률수준 이상 비식별되도록
- m-유일성
  - 원본 데이터와 동일한 속성 값의 조합이 비식별 결과 데이터에 최소 m개 존재해야 재식별 위험성 낮음



**정형 데이터 품질 진단 방법**

- 메타데이터 수집 및 분석
- 칼럼 속성 분석
- 값의 허용 범위 분석
- 누락값 분석
- 유일값 분석
- 구조 분석



**모형화** - 데이터 분석 절차에서 복잡한 문제 단순화를 통해 > 문제를 변수들 간 관계로 정의



진단분석 - 원인은 무엇인지 파악

예측분석 - 앞으로 어떻게 될 것인지 파악

처방분석 - 어떻게 대처해야 하는지 파악

기술분석 - 무엇이 발생했는지 파악



**데이터 분석 성숙도 모델**

성숙도 수준 : 도입 - 활용 - 확산 - 최적화



#### 2과목

단계적 선택법 - 전진 후 후진 > 새롭게 유의하지 않은 변수들은 제거 가능(제거된 애는 다시 포함 x)



- 파생변수
  - 의미부여하는 함수
  - 세분화, 고객행동 예측 등에 유용하게 사용
  - 특정한 상황에만 유의미하지 않게, 대표성 가지도록 해야
- 요약변수
  - 수집된 정보를 분석에 맞게 종합한 변수
  - 데이터마트에서 가장 기본적 변수
  - 결측치 처리 및 이상값 처리에 유의해야



데이터 축소 - 특이값 분해, 음수 미포함 행렬분해



P(A|F) = P(A∩F)/P(F)

P(A∩F) = P(A)P(F|A)

P(F) = P(F|A)P(A) + P(F|B)P(B) + P(F|C)P(C)



어떤 학생이 80-85 사이 점수 받을 확률

\> Z1 = (80-80)/10 = 0 \>> (X-μ)/σ >> σ2이 분산

\> Z2 = (85-80)/10 = 0.5 

\> P(80 <= X <= 85) = P(0 <= Z <= 0.5) = P(Z>=0.5) - P(Z<= 0.0)



**피어슨** : -1 ~ 1 사이 값 / X와 Y간 선형상관관계

**스피어만** : 0 ~ 1 값 / 직선이 아닌 곡선(일정 비율로 가는 게 아니라는 뜻) / 두 변수간 연관관계

​					순위 이용하는 경우의 상관계수(이상점 있거나 표본크기 작을 때 유용)



차원의 저주 : 학습을 위해 차원이 올라가면 데이터수는 줄어들고 성능이 저하

차원의 증가 : 파라미터의 증가 및 마라미터 간 복잡한 관계의 증가로 과적합 발생 가능성 커짐



**층화 추출**

층별로 표본 배정하는 방법

- 비례 배분법
  - 추출단위수에 비례해서
- 네이만 배분법
  - 층 크기와 층별 변동 정도를 동시 고려
- 최적 배분법
  - 분산 최소화, 비용 최소화



**불균형 데이터 처리 ** : 각 클래스가 가지고 있는 데이터의 양 차이가 클수록

- 가중치 균형법, 오버샘플링, 언더 샘플링



표본 크기가 커질수록 표준오차는 줄어듦

표본 분포의 평균은 모집단의 평균과 동일

모집단의 표준편차가 σ면 표본분포의 표준편차는 σ/√n



**이산확률분포** : 베르누이, 이항, 음이항, 다항, 포아송, 기하, 초기하

**연속확률분포** : 지수, 정규, F-분포, 표준정규 ...



모집단 정규고 모분산을 모르면 >> 표본 30 이상이면 정규, 이하면 t-분포



#### 3과목

활성화 함수 : 입력신호의 총합을 출력신호로 변환

손실 함수 : 신경망이 출력한 값과 실제값과의 오차에 대한 함수



**특징맵 출력 크기** : (입력 높이 + 2*패딩값 - 필터 높이)/스트라이드 + 1



다중공선성은 3개 이상읟 ㅗㄱ립변수 간 상관관계가 문제 없어야



**SVM**

- 선형, 비선형 분류 가능
- 분류, 회귀, 특이점 판별에 활용되는 지도학습 기법

- 주요 요소 : 벡터, 결정영역, 초평면, 서포트벡터, 마진 ...



정밀도 = true 예측 중 실제 true

재현율 = 실제 true 중 예측 true



holdout 교차검증 : 학습, 검증, 테스트 세 개로 구분



자기상관 : 시차값 사이 선형관계 >> 자기상관성 기반으로 패턴이 지속 >> 예측 좋아짐 >> 자기 회귀모형

정상성 : 평균과 분산이 일정한 경우

이동평균 : 일정기간을 시계열을 이동하면서 분산 계산



랜덤 포레스트 : 분류, 회귀 모두 가능 / 예측 변동성 적음



#### 4과목

ROC : Y축은 민감도, X축은 1-특이도 / 이진분류기 성능 평가 지표



표본추출 방법 > 군집 추출 시행하면 표본크기가 같은 경우 표본오차가 증가할 수 ㅇ

층화추출 : 각 집단 내에 특징 집단 나누고, 해당 집단에서 표본 추출하는 방법



매개변수 : 가중치, 편향 ㅇ / 모델 내부에서 결정되는 변수(알고리즘 통해 자동학습)



딥러닝의 하이퍼파라미터 종류 : 학습률, 배치크기, 은닉층뉴런개수, 훈련반복횟수



K-평균 군집분석 : 군집중심점 선택 > 가까운 애들 찾아서 묶어



F1 SCORE : 2*(pre - re) / (pre + re)



다층 퍼셉트론 : 은닉층 ㅇ / 활성화함수인 계단함수 이용 / 가중치, 편향 매개변수 / 비선형 영역 표현 가능



**적합도 검정** : 관측값들이 어떤 이론적 분포를 따르고 있는지 검정, 한 개의 요인 대상으로 / 특정 분포함수와 얼마나 맞는지 검정
